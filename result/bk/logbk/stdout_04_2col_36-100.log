[2016-12-07 17:25:47] multi process started
[2016-12-07 17:25:47] current cores used: 4/20
[2016-12-07 17:25:47] Task parse_set_036 start...
[2016-12-07 17:25:47] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_036 "parse_set_036" "./test" &
[2016-12-07 17:25:56] reading file: ericsson_umts_demo/set_036
[2016-12-07 17:25:59] current cores used: 6/20
[2016-12-07 17:25:59] Task parse_set_037 start...
[2016-12-07 17:25:59] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_037 "parse_set_037" "./test" &
[2016-12-07 17:26:03] finish reading file: ericsson_umts_demo/set_036
[2016-12-07 17:26:09] reading file: ericsson_umts_demo/set_037
[2016-12-07 17:26:11] current cores used: 8/20
[2016-12-07 17:26:11] Task parse_set_038 start...
[2016-12-07 17:26:11] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_038 "parse_set_038" "./test" &
[2016-12-07 17:26:16] finish reading file: ericsson_umts_demo/set_037
[2016-12-07 17:26:24] current cores used: 10/20
[2016-12-07 17:26:24] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:26:25] reading file: ericsson_umts_demo/set_038
[2016-12-07 17:26:33] finish reading file: ericsson_umts_demo/set_038
[2016-12-07 17:27:54] Job: parse_set_036: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 6, 10.26.127.60): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 6, 10.26.127.60): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

[2016-12-07 17:28:24] current cores used: 8/20
[2016-12-07 17:28:24] Task parse_set_039 start...
[2016-12-07 17:28:24] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_039 "parse_set_039" "./test" &
[2016-12-07 17:28:32] reading file: ericsson_umts_demo/set_039
[2016-12-07 17:28:36] current cores used: 10/20
[2016-12-07 17:28:36] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:28:43] finish reading file: ericsson_umts_demo/set_039
[2016-12-07 17:29:35] start writing file: ./test/set_037.txt
[2016-12-07 17:30:36] current cores used: 10/20
[2016-12-07 17:30:36] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:30:45] finish writing file: ./test/set_037.txt
[2016-12-07 17:31:34] start writing file: ./test/set_039.txt
[2016-12-07 17:31:54] start writing file: ./test/set_038.txt
[2016-12-07 17:32:36] current cores used: 8/20
[2016-12-07 17:32:36] Task parse_set_040 start...
[2016-12-07 17:32:36] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_040 "parse_set_040" "./test" &
[2016-12-07 17:32:45] reading file: ericsson_umts_demo/set_040
[2016-12-07 17:32:48] current cores used: 10/20
[2016-12-07 17:32:48] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:32:53] finish reading file: ericsson_umts_demo/set_040
[2016-12-07 17:33:05] finish writing file: ./test/set_039.txt
[2016-12-07 17:33:27] finish writing file: ./test/set_038.txt
[2016-12-07 17:34:48] current cores used: 6/20
[2016-12-07 17:34:48] Task parse_set_041 start...
[2016-12-07 17:34:48] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_041 "parse_set_041" "./test" &
[2016-12-07 17:34:49] start writing file: ./test/set_040.txt
[2016-12-07 17:34:58] reading file: ericsson_umts_demo/set_041
[2016-12-07 17:35:00] current cores used: 8/20
[2016-12-07 17:35:00] Task parse_set_042 start...
[2016-12-07 17:35:00] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_042 "parse_set_042" "./test" &
[2016-12-07 17:35:05] finish reading file: ericsson_umts_demo/set_041
[2016-12-07 17:35:10] reading file: ericsson_umts_demo/set_042
[2016-12-07 17:35:12] current cores used: 10/20
[2016-12-07 17:35:12] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:35:16] finish reading file: ericsson_umts_demo/set_042
[2016-12-07 17:36:11] finish writing file: ./test/set_040.txt
[2016-12-07 17:37:13] current cores used: 8/20
[2016-12-07 17:37:13] Task parse_set_043 start...
[2016-12-07 17:37:13] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_043 "parse_set_043" "./test" &
[2016-12-07 17:37:21] reading file: ericsson_umts_demo/set_043
[2016-12-07 17:37:25] current cores used: 10/20
[2016-12-07 17:37:25] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:37:27] start writing file: ./test/set_041.txt
[2016-12-07 17:37:29] finish reading file: ericsson_umts_demo/set_043
[2016-12-07 17:37:45] start writing file: ./test/set_042.txt
[2016-12-07 17:39:22] finish writing file: ./test/set_041.txt
[2016-12-07 17:39:25] current cores used: 8/20
[2016-12-07 17:39:25] Task parse_set_044 start...
[2016-12-07 17:39:25] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_044 "parse_set_044" "./test" &
[2016-12-07 17:39:34] reading file: ericsson_umts_demo/set_044
[2016-12-07 17:39:37] current cores used: 10/20
[2016-12-07 17:39:37] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:39:40] finish writing file: ./test/set_042.txt
[2016-12-07 17:39:41] finish reading file: ericsson_umts_demo/set_044
[2016-12-07 17:40:41] Job: parse_set_043: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.60): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.60): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-07 17:41:37] current cores used: 6/20
[2016-12-07 17:41:37] Task parse_set_045 start...
[2016-12-07 17:41:37] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_045 "parse_set_045" "./test" &
[2016-12-07 17:41:46] reading file: ericsson_umts_demo/set_045
[2016-12-07 17:41:49] current cores used: 8/20
[2016-12-07 17:41:49] Task parse_set_046 start...
[2016-12-07 17:41:49] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_046 "parse_set_046" "./test" &
[2016-12-07 17:41:51] finish reading file: ericsson_umts_demo/set_045
[2016-12-07 17:41:58] reading file: ericsson_umts_demo/set_046
[2016-12-07 17:42:01] current cores used: 10/20
[2016-12-07 17:42:01] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:42:05] finish reading file: ericsson_umts_demo/set_046
[2016-12-07 17:42:06] start writing file: ./test/set_044.txt
[2016-12-07 17:43:13] finish writing file: ./test/set_044.txt
[2016-12-07 17:44:01] current cores used: 8/20
[2016-12-07 17:44:01] Task parse_set_047 start...
[2016-12-07 17:44:01] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_047 "parse_set_047" "./test" &
[2016-12-07 17:44:10] reading file: ericsson_umts_demo/set_047
[2016-12-07 17:44:13] current cores used: 10/20
[2016-12-07 17:44:13] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:44:17] finish reading file: ericsson_umts_demo/set_047
[2016-12-07 17:46:14] current cores used: 10/20
[2016-12-07 17:46:14] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:46:52] start writing file: ./test/set_047.txt
[2016-12-07 17:47:10] start writing file: ./test/set_046.txt
[2016-12-07 17:47:54] start writing file: ./test/set_045.txt
[2016-12-07 17:48:14] current cores used: 10/20
[2016-12-07 17:48:14] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:48:28] finish writing file: ./test/set_047.txt
[2016-12-07 17:48:34] finish writing file: ./test/set_046.txt
[2016-12-07 17:49:29] finish writing file: ./test/set_045.txt
[2016-12-07 17:50:14] current cores used: 4/20
[2016-12-07 17:50:14] Task parse_set_048 start...
[2016-12-07 17:50:14] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_048 "parse_set_048" "./test" &
[2016-12-07 17:50:22] reading file: ericsson_umts_demo/set_048
[2016-12-07 17:50:26] current cores used: 6/20
[2016-12-07 17:50:26] Task parse_set_049 start...
[2016-12-07 17:50:26] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_049 "parse_set_049" "./test" &
[2016-12-07 17:50:28] finish reading file: ericsson_umts_demo/set_048
[2016-12-07 17:50:35] reading file: ericsson_umts_demo/set_049
[2016-12-07 17:50:38] current cores used: 8/20
[2016-12-07 17:50:38] Task parse_set_050 start...
[2016-12-07 17:50:38] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_050 "parse_set_050" "./test" &
[2016-12-07 17:50:40] finish reading file: ericsson_umts_demo/set_049
[2016-12-07 17:50:50] reading file: ericsson_umts_demo/set_050
[2016-12-07 17:50:50] current cores used: 10/20
[2016-12-07 17:50:50] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:50:58] finish reading file: ericsson_umts_demo/set_050
[2016-12-07 17:52:50] current cores used: 10/20
[2016-12-07 17:52:50] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:53:53] start writing file: ./test/set_049.txt
[2016-12-07 17:54:50] current cores used: 10/20
[2016-12-07 17:54:50] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:55:13] start writing file: ./test/set_050.txt
[2016-12-07 17:55:29] start writing file: ./test/set_048.txt
[2016-12-07 17:55:52] finish writing file: ./test/set_049.txt
[2016-12-07 17:56:50] current cores used: 8/20
[2016-12-07 17:56:50] Task parse_set_051 start...
[2016-12-07 17:56:50] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_051 "parse_set_051" "./test" &
[2016-12-07 17:56:59] reading file: ericsson_umts_demo/set_051
[2016-12-07 17:57:03] current cores used: 10/20
[2016-12-07 17:57:03] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:57:07] finish reading file: ericsson_umts_demo/set_051
[2016-12-07 17:57:13] finish writing file: ./test/set_050.txt
[2016-12-07 17:57:27] finish writing file: ./test/set_048.txt
[2016-12-07 17:59:01] start writing file: ./test/set_051.txt
[2016-12-07 17:59:03] current cores used: 6/20
[2016-12-07 17:59:03] Task parse_set_052 start...
[2016-12-07 17:59:03] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_052 "parse_set_052" "./test" &
[2016-12-07 17:59:12] reading file: ericsson_umts_demo/set_052
[2016-12-07 17:59:15] current cores used: 8/20
[2016-12-07 17:59:15] Task parse_set_053 start...
[2016-12-07 17:59:15] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_053 "parse_set_053" "./test" &
[2016-12-07 17:59:17] finish reading file: ericsson_umts_demo/set_052
[2016-12-07 17:59:24] reading file: ericsson_umts_demo/set_053
[2016-12-07 17:59:27] current cores used: 10/20
[2016-12-07 17:59:27] reached max num of job (4/4), retry again in 2 min
[2016-12-07 17:59:30] finish reading file: ericsson_umts_demo/set_053
[2016-12-07 18:00:15] finish writing file: ./test/set_051.txt
[2016-12-07 18:01:27] current cores used: 4/20
[2016-12-07 18:01:27] Task parse_set_054 start...
[2016-12-07 18:01:27] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_054 "parse_set_054" "./test" &
[2016-12-07 18:01:35] reading file: ericsson_umts_demo/set_054
[2016-12-07 18:01:39] current cores used: 6/20
[2016-12-07 18:01:39] Task parse_set_055 start...
[2016-12-07 18:01:39] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_055 "parse_set_055" "./test" &
[2016-12-07 18:01:46] finish reading file: ericsson_umts_demo/set_054
[2016-12-07 18:01:48] reading file: ericsson_umts_demo/set_055
[2016-12-07 18:01:51] current cores used: 8/20
[2016-12-07 18:01:51] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:01:59] finish reading file: ericsson_umts_demo/set_055
[2016-12-07 18:03:51] current cores used: 8/20
[2016-12-07 18:03:51] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:04:56] start writing file: ./test/set_053.txt
[2016-12-07 18:05:51] current cores used: 8/20
[2016-12-07 18:05:51] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:06:08] finish writing file: ./test/set_053.txt
[2016-12-07 18:06:14] start writing file: ./test/set_052.txt
[2016-12-07 18:07:30] finish writing file: ./test/set_052.txt
[2016-12-07 18:07:51] current cores used: 4/20
[2016-12-07 18:07:51] Task parse_set_056 start...
[2016-12-07 18:07:51] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_056 "parse_set_056" "./test" &
[2016-12-07 18:08:00] reading file: ericsson_umts_demo/set_056
[2016-12-07 18:08:04] current cores used: 6/20
[2016-12-07 18:08:04] Task parse_set_057 start...
[2016-12-07 18:08:04] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_057 "parse_set_057" "./test" &
[2016-12-07 18:08:07] finish reading file: ericsson_umts_demo/set_056
[2016-12-07 18:08:13] reading file: ericsson_umts_demo/set_057
[2016-12-07 18:08:16] current cores used: 8/20
[2016-12-07 18:08:16] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:08:29] finish reading file: ericsson_umts_demo/set_057
[2016-12-07 18:10:16] current cores used: 8/20
[2016-12-07 18:10:16] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:10:31] start writing file: ./test/set_056.txt
[2016-12-07 18:10:52] Job: parse_set_057: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.60): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.60): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

[2016-12-07 18:11:46] finish writing file: ./test/set_056.txt
[2016-12-07 18:12:16] current cores used: 4/20
[2016-12-07 18:12:16] Task parse_set_058 start...
[2016-12-07 18:12:16] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_058 "parse_set_058" "./test" &
[2016-12-07 18:12:24] reading file: ericsson_umts_demo/set_058
[2016-12-07 18:12:28] current cores used: 6/20
[2016-12-07 18:12:28] Task parse_set_059 start...
[2016-12-07 18:12:28] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_059 "parse_set_059" "./test" &
[2016-12-07 18:12:31] finish reading file: ericsson_umts_demo/set_058
[2016-12-07 18:12:37] reading file: ericsson_umts_demo/set_059
[2016-12-07 18:12:40] current cores used: 8/20
[2016-12-07 18:12:40] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:12:42] finish reading file: ericsson_umts_demo/set_059
[2016-12-07 18:14:40] current cores used: 12/20
[2016-12-07 18:14:40] reached max num of job (5/4), retry again in 2 min
[2016-12-07 18:15:09] start writing file: ./test/set_058.txt
[2016-12-07 18:15:19] start writing file: ./test/set_059.txt
[2016-12-07 18:16:44] current cores used: 12/20
[2016-12-07 18:16:44] reached max num of job (5/4), retry again in 2 min
[2016-12-07 18:17:37] finish writing file: ./test/set_058.txt
[2016-12-07 18:17:49] finish writing file: ./test/set_059.txt
[2016-12-07 18:18:45] current cores used: 8/20
[2016-12-07 18:18:45] Task parse_set_060 start...
[2016-12-07 18:18:45] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_060 "parse_set_060" "./test" &
[2016-12-07 18:18:59] current cores used: 8/20
[2016-12-07 18:18:59] last job submit (parse_set_060) not completed, retry again in 12 sec
[2016-12-07 18:19:06] reading file: ericsson_umts_demo/set_060
[2016-12-07 18:19:11] current cores used: 10/20
[2016-12-07 18:19:11] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:19:12] finish reading file: ericsson_umts_demo/set_060
[2016-12-07 18:21:11] current cores used: 10/20
[2016-12-07 18:21:11] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:21:32] Job: parse_set_054: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 7, 10.26.127.52): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 7, 10.26.127.52): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-07 18:23:11] current cores used: 8/20
[2016-12-07 18:23:11] Task parse_set_061 start...
[2016-12-07 18:23:11] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_061 "parse_set_061" "./test" &
[2016-12-07 18:23:20] reading file: ericsson_umts_demo/set_061
[2016-12-07 18:23:23] current cores used: 10/20
[2016-12-07 18:23:23] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:23:25] finish reading file: ericsson_umts_demo/set_061
[2016-12-07 18:25:23] current cores used: 6/20
[2016-12-07 18:25:23] Task parse_set_062 start...
[2016-12-07 18:25:23] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_062 "parse_set_062" "./test" &
[2016-12-07 18:25:33] reading file: ericsson_umts_demo/set_062
[2016-12-07 18:25:35] current cores used: 8/20
[2016-12-07 18:25:35] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:25:38] finish reading file: ericsson_umts_demo/set_062
[2016-12-07 18:27:35] current cores used: 12/20
[2016-12-07 18:27:35] reached max num of job (5/4), retry again in 2 min
[2016-12-07 18:27:58] start writing file: ./test/set_062.txt
[2016-12-07 18:28:03] start writing file: ./test/set_060.txt
[2016-12-07 18:29:35] current cores used: 12/20
[2016-12-07 18:29:35] reached max num of job (5/4), retry again in 2 min
[2016-12-07 18:29:47] start writing file: ./test/set_055.txt
[2016-12-07 18:30:05] start writing file: ./test/set_061.txt
[2016-12-07 18:30:19] finish writing file: ./test/set_062.txt
[2016-12-07 18:30:33] finish writing file: ./test/set_060.txt
[2016-12-07 18:31:34] finish writing file: ./test/set_061.txt
[2016-12-07 18:31:36] current cores used: 6/20
[2016-12-07 18:31:36] Task parse_set_063 start...
[2016-12-07 18:31:36] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_063 "parse_set_063" "./test" &
[2016-12-07 18:31:42] finish writing file: ./test/set_055.txt
[2016-12-07 18:31:45] reading file: ericsson_umts_demo/set_063
[2016-12-07 18:31:48] current cores used: 6/20
[2016-12-07 18:31:48] Task parse_set_064 start...
[2016-12-07 18:31:48] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_064 "parse_set_064" "./test" &
[2016-12-07 18:31:58] finish reading file: ericsson_umts_demo/set_063
[2016-12-07 18:31:59] reading file: ericsson_umts_demo/set_064
[2016-12-07 18:32:00] current cores used: 8/20
[2016-12-07 18:32:00] Task parse_set_065 start...
[2016-12-07 18:32:00] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_065 "parse_set_065" "./test" &
[2016-12-07 18:32:08] finish reading file: ericsson_umts_demo/set_064
[2016-12-07 18:32:12] reading file: ericsson_umts_demo/set_065
[2016-12-07 18:32:12] current cores used: 10/20
[2016-12-07 18:32:12] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:32:19] finish reading file: ericsson_umts_demo/set_065
[2016-12-07 18:34:12] current cores used: 10/20
[2016-12-07 18:34:12] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:34:35] Job: parse_set_064: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.60): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.60): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

[2016-12-07 18:36:12] current cores used: 8/20
[2016-12-07 18:36:12] Task parse_set_066 start...
[2016-12-07 18:36:12] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_066 "parse_set_066" "./test" &
[2016-12-07 18:36:21] reading file: ericsson_umts_demo/set_066
[2016-12-07 18:36:24] current cores used: 10/20
[2016-12-07 18:36:24] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:36:26] finish reading file: ericsson_umts_demo/set_066
[2016-12-07 18:38:24] current cores used: 6/20
[2016-12-07 18:38:24] Task parse_set_067 start...
[2016-12-07 18:38:24] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_067 "parse_set_067" "./test" &
[2016-12-07 18:38:33] reading file: ericsson_umts_demo/set_067
[2016-12-07 18:38:36] current cores used: 8/20
[2016-12-07 18:38:36] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:38:39] finish reading file: ericsson_umts_demo/set_067
[2016-12-07 18:38:58] start writing file: ./test/set_065.txt
[2016-12-07 18:40:06] finish writing file: ./test/set_065.txt
[2016-12-07 18:40:34] start writing file: ./test/set_063.txt
[2016-12-07 18:40:36] start writing file: ./test/set_067.txt
[2016-12-07 18:40:37] current cores used: 6/20
[2016-12-07 18:40:37] Task parse_set_068 start...
[2016-12-07 18:40:37] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_068 "parse_set_068" "./test" &
[2016-12-07 18:40:46] reading file: ericsson_umts_demo/set_068
[2016-12-07 18:40:49] current cores used: 8/20
[2016-12-07 18:40:49] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:40:54] finish reading file: ericsson_umts_demo/set_068
[2016-12-07 18:42:06] finish writing file: ./test/set_063.txt
[2016-12-07 18:42:14] finish writing file: ./test/set_067.txt
[2016-12-07 18:42:49] current cores used: 4/20
[2016-12-07 18:42:49] Task parse_set_069 start...
[2016-12-07 18:42:49] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_069 "parse_set_069" "./test" &
[2016-12-07 18:42:57] reading file: ericsson_umts_demo/set_069
[2016-12-07 18:43:01] current cores used: 6/20
[2016-12-07 18:43:01] Task parse_set_070 start...
[2016-12-07 18:43:01] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_070 "parse_set_070" "./test" &
[2016-12-07 18:43:04] finish reading file: ericsson_umts_demo/set_069
[2016-12-07 18:43:10] reading file: ericsson_umts_demo/set_070
[2016-12-07 18:43:13] current cores used: 8/20
[2016-12-07 18:43:13] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:43:18] finish reading file: ericsson_umts_demo/set_070
[2016-12-07 18:43:34] start writing file: ./test/set_066.txt
[2016-12-07 18:44:54] finish writing file: ./test/set_066.txt
[2016-12-07 18:45:13] current cores used: 6/20
[2016-12-07 18:45:13] Task parse_set_071 start...
[2016-12-07 18:45:13] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_071 "parse_set_071" "./test" &
[2016-12-07 18:45:22] reading file: ericsson_umts_demo/set_071
[2016-12-07 18:45:25] current cores used: 8/20
[2016-12-07 18:45:25] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:45:29] finish reading file: ericsson_umts_demo/set_071
[2016-12-07 18:47:25] current cores used: 8/20
[2016-12-07 18:47:25] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:49:25] current cores used: 12/20
[2016-12-07 18:49:25] reached max num of job (5/4), retry again in 2 min
[2016-12-07 18:51:26] current cores used: 12/20
[2016-12-07 18:51:26] reached max num of job (5/4), retry again in 2 min
[2016-12-07 18:52:42] start writing file: ./test/set_069.txt
[2016-12-07 18:53:26] current cores used: 8/20
[2016-12-07 18:53:26] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:53:36] start writing file: ./test/set_071.txt
[2016-12-07 18:53:52] finish writing file: ./test/set_069.txt
[2016-12-07 18:54:55] finish writing file: ./test/set_071.txt
[2016-12-07 18:55:26] current cores used: 4/20
[2016-12-07 18:55:26] Task parse_set_072 start...
[2016-12-07 18:55:26] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_072 "parse_set_072" "./test" &
[2016-12-07 18:55:35] reading file: ericsson_umts_demo/set_072
[2016-12-07 18:55:38] current cores used: 6/20
[2016-12-07 18:55:38] Task parse_set_073 start...
[2016-12-07 18:55:38] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_073 "parse_set_073" "./test" &
[2016-12-07 18:55:44] finish reading file: ericsson_umts_demo/set_072
[2016-12-07 18:55:47] reading file: ericsson_umts_demo/set_073
[2016-12-07 18:55:50] current cores used: 8/20
[2016-12-07 18:55:50] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:55:54] finish reading file: ericsson_umts_demo/set_073
[2016-12-07 18:57:50] current cores used: 8/20
[2016-12-07 18:57:50] reached max num of job (4/4), retry again in 2 min
[2016-12-07 18:59:50] current cores used: 8/20
[2016-12-07 18:59:50] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:00:38] Job: parse_set_068: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.60): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:230)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	... 11 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:230)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	... 11 more
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.60): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:230)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	... 11 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:230)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	... 11 more

[2016-12-07 19:01:41] start writing file: ./test/set_070.txt
[2016-12-07 19:01:50] current cores used: 10/20
[2016-12-07 19:01:50] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:03:03] finish writing file: ./test/set_070.txt
[2016-12-07 19:03:46] start writing file: ./test/set_073.txt
[2016-12-07 19:03:51] current cores used: 8/20
[2016-12-07 19:03:51] Task parse_set_074 start...
[2016-12-07 19:03:51] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_074 "parse_set_074" "./test" &
[2016-12-07 19:04:00] reading file: ericsson_umts_demo/set_074
[2016-12-07 19:04:03] current cores used: 10/20
[2016-12-07 19:04:03] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:04:06] finish reading file: ericsson_umts_demo/set_074
[2016-12-07 19:05:02] finish writing file: ./test/set_073.txt
[2016-12-07 19:05:39] start writing file: ./test/set_072.txt
[2016-12-07 19:05:59] start writing file: ./test/set_074.txt
[2016-12-07 19:06:03] current cores used: 4/20
[2016-12-07 19:06:03] Task parse_set_075 start...
[2016-12-07 19:06:03] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_075 "parse_set_075" "./test" &
[2016-12-07 19:06:13] reading file: ericsson_umts_demo/set_075
[2016-12-07 19:06:15] current cores used: 6/20
[2016-12-07 19:06:15] Task parse_set_076 start...
[2016-12-07 19:06:15] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_076 "parse_set_076" "./test" &
[2016-12-07 19:06:19] finish reading file: ericsson_umts_demo/set_075
[2016-12-07 19:06:24] reading file: ericsson_umts_demo/set_076
[2016-12-07 19:06:27] current cores used: 8/20
[2016-12-07 19:06:27] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:06:41] finish reading file: ericsson_umts_demo/set_076
[2016-12-07 19:07:02] finish writing file: ./test/set_072.txt
[2016-12-07 19:07:31] finish writing file: ./test/set_074.txt
[2016-12-07 19:08:27] current cores used: 4/20
[2016-12-07 19:08:27] Task parse_set_077 start...
[2016-12-07 19:08:27] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_077 "parse_set_077" "./test" &
[2016-12-07 19:08:35] reading file: ericsson_umts_demo/set_077
[2016-12-07 19:08:39] current cores used: 6/20
[2016-12-07 19:08:39] Task parse_set_078 start...
[2016-12-07 19:08:39] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_078 "parse_set_078" "./test" &
[2016-12-07 19:08:42] finish reading file: ericsson_umts_demo/set_077
[2016-12-07 19:08:48] reading file: ericsson_umts_demo/set_078
[2016-12-07 19:08:51] current cores used: 8/20
[2016-12-07 19:08:51] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:08:54] finish reading file: ericsson_umts_demo/set_078
[2016-12-07 19:10:44] start writing file: ./test/set_077.txt
[2016-12-07 19:10:51] current cores used: 8/20
[2016-12-07 19:10:51] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:11:59] finish writing file: ./test/set_077.txt
[2016-12-07 19:12:51] current cores used: 6/20
[2016-12-07 19:12:51] Task parse_set_079 start...
[2016-12-07 19:12:51] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_079 "parse_set_079" "./test" &
[2016-12-07 19:13:00] reading file: ericsson_umts_demo/set_079
[2016-12-07 19:13:03] current cores used: 8/20
[2016-12-07 19:13:03] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:13:06] finish reading file: ericsson_umts_demo/set_079
[2016-12-07 19:15:04] current cores used: 8/20
[2016-12-07 19:15:04] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:15:18] Job: parse_set_075: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.60): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.60): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

[2016-12-07 19:15:35] start writing file: ./test/set_079.txt
[2016-12-07 19:16:47] finish writing file: ./test/set_079.txt
[2016-12-07 19:17:04] current cores used: 4/20
[2016-12-07 19:17:04] Task parse_set_080 start...
[2016-12-07 19:17:04] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_080 "parse_set_080" "./test" &
[2016-12-07 19:17:13] reading file: ericsson_umts_demo/set_080
[2016-12-07 19:17:16] current cores used: 6/20
[2016-12-07 19:17:16] Task parse_set_081 start...
[2016-12-07 19:17:16] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_081 "parse_set_081" "./test" &
[2016-12-07 19:17:17] finish reading file: ericsson_umts_demo/set_080
[2016-12-07 19:17:25] reading file: ericsson_umts_demo/set_081
[2016-12-07 19:17:28] current cores used: 8/20
[2016-12-07 19:17:28] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:17:32] finish reading file: ericsson_umts_demo/set_081
[2016-12-07 19:18:30] start writing file: ./test/set_078.txt
[2016-12-07 19:19:28] current cores used: 8/20
[2016-12-07 19:19:28] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:19:33] start writing file: ./test/set_080.txt
[2016-12-07 19:19:48] finish writing file: ./test/set_078.txt
[2016-12-07 19:20:48] finish writing file: ./test/set_080.txt
[2016-12-07 19:21:28] current cores used: 4/20
[2016-12-07 19:21:28] Task parse_set_082 start...
[2016-12-07 19:21:28] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_082 "parse_set_082" "./test" &
[2016-12-07 19:21:36] reading file: ericsson_umts_demo/set_082
[2016-12-07 19:21:40] current cores used: 6/20
[2016-12-07 19:21:40] Task parse_set_083 start...
[2016-12-07 19:21:40] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_083 "parse_set_083" "./test" &
[2016-12-07 19:21:43] finish reading file: ericsson_umts_demo/set_082
[2016-12-07 19:21:50] reading file: ericsson_umts_demo/set_083
[2016-12-07 19:21:52] current cores used: 8/20
[2016-12-07 19:21:52] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:21:57] finish reading file: ericsson_umts_demo/set_083
[2016-12-07 19:23:40] start writing file: ./test/set_082.txt
[2016-12-07 19:23:52] current cores used: 8/20
[2016-12-07 19:23:52] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:24:47] finish writing file: ./test/set_082.txt
[2016-12-07 19:25:53] current cores used: 6/20
[2016-12-07 19:25:53] Task parse_set_084 start...
[2016-12-07 19:25:53] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_084 "parse_set_084" "./test" &
[2016-12-07 19:26:01] reading file: ericsson_umts_demo/set_084
[2016-12-07 19:26:05] current cores used: 8/20
[2016-12-07 19:26:05] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:26:05] finish reading file: ericsson_umts_demo/set_084
[2016-12-07 19:28:05] current cores used: 8/20
[2016-12-07 19:28:05] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:28:10] start writing file: ./test/set_084.txt
[2016-12-07 19:28:20] start writing file: ./test/set_081.txt
[2016-12-07 19:29:38] finish writing file: ./test/set_084.txt
[2016-12-07 19:29:58] finish writing file: ./test/set_081.txt
[2016-12-07 19:30:05] current cores used: 4/20
[2016-12-07 19:30:05] Task parse_set_085 start...
[2016-12-07 19:30:05] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_085 "parse_set_085" "./test" &
[2016-12-07 19:30:06] start writing file: ./test/set_083.txt
[2016-12-07 19:30:12] start writing file: ./test/set_076.txt
[2016-12-07 19:30:15] reading file: ericsson_umts_demo/set_085
[2016-12-07 19:30:17] current cores used: 6/20
[2016-12-07 19:30:17] Task parse_set_086 start...
[2016-12-07 19:30:17] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_086 "parse_set_086" "./test" &
[2016-12-07 19:30:20] finish reading file: ericsson_umts_demo/set_085
[2016-12-07 19:30:26] reading file: ericsson_umts_demo/set_086
[2016-12-07 19:30:29] current cores used: 8/20
[2016-12-07 19:30:29] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:30:34] finish reading file: ericsson_umts_demo/set_086
[2016-12-07 19:31:26] finish writing file: ./test/set_083.txt
[2016-12-07 19:31:30] finish writing file: ./test/set_076.txt
[2016-12-07 19:32:27] start writing file: ./test/set_085.txt
[2016-12-07 19:32:29] current cores used: 4/20
[2016-12-07 19:32:29] Task parse_set_087 start...
[2016-12-07 19:32:29] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_087 "parse_set_087" "./test" &
[2016-12-07 19:32:38] reading file: ericsson_umts_demo/set_087
[2016-12-07 19:32:41] current cores used: 6/20
[2016-12-07 19:32:41] Task parse_set_088 start...
[2016-12-07 19:32:41] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_088 "parse_set_088" "./test" &
[2016-12-07 19:32:50] finish reading file: ericsson_umts_demo/set_087
[2016-12-07 19:32:50] reading file: ericsson_umts_demo/set_088
[2016-12-07 19:32:53] current cores used: 8/20
[2016-12-07 19:32:53] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:32:57] finish reading file: ericsson_umts_demo/set_088
[2016-12-07 19:33:42] finish writing file: ./test/set_085.txt
[2016-12-07 19:34:53] current cores used: 6/20
[2016-12-07 19:34:53] Task parse_set_089 start...
[2016-12-07 19:34:53] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_089 "parse_set_089" "./test" &
[2016-12-07 19:35:03] reading file: ericsson_umts_demo/set_089
[2016-12-07 19:35:06] current cores used: 8/20
[2016-12-07 19:35:06] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:35:08] finish reading file: ericsson_umts_demo/set_089
[2016-12-07 19:37:00] start writing file: ./test/set_089.txt
[2016-12-07 19:37:06] current cores used: 8/20
[2016-12-07 19:37:06] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:38:05] finish writing file: ./test/set_089.txt
[2016-12-07 19:39:06] current cores used: 6/20
[2016-12-07 19:39:06] Task parse_set_090 start...
[2016-12-07 19:39:06] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_090 "parse_set_090" "./test" &
[2016-12-07 19:39:14] reading file: ericsson_umts_demo/set_090
[2016-12-07 19:39:18] current cores used: 8/20
[2016-12-07 19:39:18] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:39:20] finish reading file: ericsson_umts_demo/set_090
[2016-12-07 19:41:16] start writing file: ./test/set_090.txt
[2016-12-07 19:41:18] current cores used: 8/20
[2016-12-07 19:41:18] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:42:24] finish writing file: ./test/set_090.txt
[2016-12-07 19:43:18] current cores used: 6/20
[2016-12-07 19:43:18] Task parse_set_091 start...
[2016-12-07 19:43:18] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_091 "parse_set_091" "./test" &
[2016-12-07 19:43:26] reading file: ericsson_umts_demo/set_091
[2016-12-07 19:43:30] current cores used: 8/20
[2016-12-07 19:43:30] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:43:31] finish reading file: ericsson_umts_demo/set_091
[2016-12-07 19:44:57] start writing file: ./test/set_088.txt
[2016-12-07 19:45:30] current cores used: 8/20
[2016-12-07 19:45:30] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:45:38] start writing file: ./test/set_091.txt
[2016-12-07 19:45:54] start writing file: ./test/set_086.txt
[2016-12-07 19:46:24] finish writing file: ./test/set_088.txt
[2016-12-07 19:47:01] finish writing file: ./test/set_091.txt
[2016-12-07 19:47:15] finish writing file: ./test/set_086.txt
[2016-12-07 19:47:30] current cores used: 2/20
[2016-12-07 19:47:30] Task parse_set_092 start...
[2016-12-07 19:47:30] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_092 "parse_set_092" "./test" &
[2016-12-07 19:47:39] reading file: ericsson_umts_demo/set_092
[2016-12-07 19:47:43] current cores used: 4/20
[2016-12-07 19:47:43] Task parse_set_093 start...
[2016-12-07 19:47:43] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_093 "parse_set_093" "./test" &
[2016-12-07 19:47:44] finish reading file: ericsson_umts_demo/set_092
[2016-12-07 19:47:47] start writing file: ./test/set_087.txt
[2016-12-07 19:47:52] reading file: ericsson_umts_demo/set_093
[2016-12-07 19:47:55] current cores used: 6/20
[2016-12-07 19:47:55] Task parse_set_094 start...
[2016-12-07 19:47:55] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_094 "parse_set_094" "./test" &
[2016-12-07 19:47:58] finish reading file: ericsson_umts_demo/set_093
[2016-12-07 19:48:04] reading file: ericsson_umts_demo/set_094
[2016-12-07 19:48:07] current cores used: 8/20
[2016-12-07 19:48:07] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:48:11] finish reading file: ericsson_umts_demo/set_094
[2016-12-07 19:49:01] finish writing file: ./test/set_087.txt
[2016-12-07 19:50:07] current cores used: 6/20
[2016-12-07 19:50:07] Task parse_set_095 start...
[2016-12-07 19:50:07] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_095 "parse_set_095" "./test" &
[2016-12-07 19:50:16] reading file: ericsson_umts_demo/set_095
[2016-12-07 19:50:19] current cores used: 8/20
[2016-12-07 19:50:19] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:50:24] start writing file: ./test/set_092.txt
[2016-12-07 19:50:28] finish reading file: ericsson_umts_demo/set_095
[2016-12-07 19:51:40] finish writing file: ./test/set_092.txt
[2016-12-07 19:52:19] current cores used: 6/20
[2016-12-07 19:52:19] Task parse_set_096 start...
[2016-12-07 19:52:19] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_096 "parse_set_096" "./test" &
[2016-12-07 19:52:27] reading file: ericsson_umts_demo/set_096
[2016-12-07 19:52:31] current cores used: 8/20
[2016-12-07 19:52:31] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:52:33] finish reading file: ericsson_umts_demo/set_096
[2016-12-07 19:54:31] current cores used: 8/20
[2016-12-07 19:54:31] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:54:43] start writing file: ./test/set_096.txt
[2016-12-07 19:55:54] finish writing file: ./test/set_096.txt
[2016-12-07 19:56:31] current cores used: 6/20
[2016-12-07 19:56:31] Task parse_set_097 start...
[2016-12-07 19:56:31] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_097 "parse_set_097" "./test" &
[2016-12-07 19:56:41] reading file: ericsson_umts_demo/set_097
[2016-12-07 19:56:43] current cores used: 8/20
[2016-12-07 19:56:43] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:56:46] finish reading file: ericsson_umts_demo/set_097
[2016-12-07 19:58:44] current cores used: 8/20
[2016-12-07 19:58:44] reached max num of job (4/4), retry again in 2 min
[2016-12-07 19:58:53] start writing file: ./test/set_097.txt
[2016-12-07 19:58:55] start writing file: ./test/set_093.txt
[2016-12-07 19:59:49] start writing file: ./test/set_095.txt
[2016-12-07 20:00:10] finish writing file: ./test/set_097.txt
[2016-12-07 20:00:14] finish writing file: ./test/set_093.txt
[2016-12-07 20:00:44] current cores used: 4/20
[2016-12-07 20:00:44] Task parse_set_098 start...
[2016-12-07 20:00:44] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_098 "parse_set_098" "./test" &
[2016-12-07 20:00:53] reading file: ericsson_umts_demo/set_098
[2016-12-07 20:00:56] current cores used: 6/20
[2016-12-07 20:00:56] Task parse_set_099 start...
[2016-12-07 20:00:56] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_099 "parse_set_099" "./test" &
[2016-12-07 20:00:57] finish reading file: ericsson_umts_demo/set_098
[2016-12-07 20:01:05] reading file: ericsson_umts_demo/set_099
[2016-12-07 20:01:08] current cores used: 8/20
[2016-12-07 20:01:08] reached max num of job (4/4), retry again in 2 min
[2016-12-07 20:01:11] finish reading file: ericsson_umts_demo/set_099
[2016-12-07 20:01:14] finish writing file: ./test/set_095.txt
[2016-12-07 20:03:01] start writing file: ./test/set_098.txt
[2016-12-07 20:03:08] current cores used: 6/20
[2016-12-07 20:03:08] Task parse_set_100 start...
[2016-12-07 20:03:08] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 1g --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_100 "parse_set_100" "./test" &
[2016-12-07 20:03:17] reading file: ericsson_umts_demo/set_100
[2016-12-07 20:03:20] multi process ended
[2016-12-07 20:03:29] finish reading file: ericsson_umts_demo/set_100
[2016-12-07 20:04:24] finish writing file: ./test/set_098.txt
[2016-12-07 20:18:14] Job: parse_set_100: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 6, 10.26.127.53): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 163515 ms
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 6, 10.26.127.53): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Executor heartbeat timed out after 163515 ms
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-07 20:21:25] start writing file: ./test/set_094.txt
[2016-12-07 20:22:36] finish writing file: ./test/set_094.txt
[2016-12-07 20:24:33] start writing file: ./test/set_099.txt
[2016-12-07 20:25:51] finish writing file: ./test/set_099.txt
