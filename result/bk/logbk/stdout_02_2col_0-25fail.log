[2016-12-06 23:24:18] multi process started
[2016-12-06 23:24:18] current cores used: 0/20
[2016-12-06 23:24:18] Task parse_set_000 start...
[2016-12-06 23:24:18] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_000 "parse_set_000" "./test" &
[2016-12-06 23:24:27] reading file: ericsson_umts_demo/set_000
[2016-12-06 23:24:30] current cores used: 2/20
[2016-12-06 23:24:30] Task parse_set_001 start...
[2016-12-06 23:24:30] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_001 "parse_set_001" "./test" &
[2016-12-06 23:24:33] finish reading file: ericsson_umts_demo/set_000
[2016-12-06 23:24:41] reading file: ericsson_umts_demo/set_001
[2016-12-06 23:24:43] current cores used: 4/20
[2016-12-06 23:24:43] Task parse_set_002 start...
[2016-12-06 23:24:43] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_002 "parse_set_002" "./test" &
[2016-12-06 23:24:47] finish reading file: ericsson_umts_demo/set_001
[2016-12-06 23:24:54] reading file: ericsson_umts_demo/set_002
[2016-12-06 23:24:55] current cores used: 6/20
[2016-12-06 23:24:55] Task parse_set_003 start...
[2016-12-06 23:24:55] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_003 "parse_set_003" "./test" &
[2016-12-06 23:25:04] finish reading file: ericsson_umts_demo/set_002
[2016-12-06 23:25:07] current cores used: 8/20
[2016-12-06 23:25:07] Task parse_set_004 start...
[2016-12-06 23:25:07] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_004 "parse_set_004" "./test" &
[2016-12-06 23:25:07] reading file: ericsson_umts_demo/set_003
[2016-12-06 23:25:14] finish reading file: ericsson_umts_demo/set_003
[2016-12-06 23:25:19] current cores used: 8/20
[2016-12-06 23:25:19] last job submit (parse_set_004) not completed, retry again in 12 sec
[2016-12-06 23:25:23] reading file: ericsson_umts_demo/set_004
[2016-12-06 23:25:31] current cores used: 10/20
[2016-12-06 23:25:31] Task parse_set_005 start...
[2016-12-06 23:25:31] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_005 "parse_set_005" "./test" &
[2016-12-06 23:25:34] finish reading file: ericsson_umts_demo/set_004
[2016-12-06 23:25:43] current cores used: 10/20
[2016-12-06 23:25:43] last job submit (parse_set_005) not completed, retry again in 12 sec
[2016-12-06 23:25:55] current cores used: 12/20
[2016-12-06 23:25:55] Task parse_set_006 start...
[2016-12-06 23:25:55] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_006 "parse_set_006" "./test" &
[2016-12-06 23:25:59] reading file: ericsson_umts_demo/set_005
[2016-12-06 23:26:08] current cores used: 12/20
[2016-12-06 23:26:08] last job submit (parse_set_006) not completed, retry again in 12 sec
[2016-12-06 23:26:20] current cores used: 12/20
[2016-12-06 23:26:20] last job submit (parse_set_006) not completed, retry again in 12 sec
[2016-12-06 23:26:34] current cores used: 12/20
[2016-12-06 23:26:34] last job submit (parse_set_006) not completed, retry again in 12 sec
[2016-12-06 23:26:46] current cores used: 12/20
[2016-12-06 23:26:46] last job submit (parse_set_006) not completed, retry again in 12 sec
[2016-12-06 23:27:01] current cores used: 12/20
[2016-12-06 23:27:01] last job submit (parse_set_006) not completed, retry again in 12 sec
[2016-12-06 23:27:04] finish reading file: ericsson_umts_demo/set_005
[2016-12-06 23:27:19] current cores used: 14/20
[2016-12-06 23:27:19] Task parse_set_007 start...
[2016-12-06 23:27:19] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_007 "parse_set_007" "./test" &
[2016-12-06 23:27:34] current cores used: 14/20
[2016-12-06 23:27:34] last job submit (parse_set_007) not completed, retry again in 12 sec
[2016-12-06 23:27:39] Job: parse_set_003: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.59): java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.59): java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

[2016-12-06 23:27:46] current cores used: 12/20
[2016-12-06 23:27:46] last job submit (parse_set_007) not completed, retry again in 12 sec
[2016-12-06 23:28:01] current cores used: 12/20
[2016-12-06 23:28:01] last job submit (parse_set_007) not completed, retry again in 12 sec
[2016-12-06 23:28:08] reading file: ericsson_umts_demo/set_006
[2016-12-06 23:28:13] current cores used: 12/20
[2016-12-06 23:28:13] last job submit (parse_set_007) not completed, retry again in 12 sec
[2016-12-06 23:28:25] finish reading file: ericsson_umts_demo/set_006
[2016-12-06 23:28:25] current cores used: 12/20
[2016-12-06 23:28:25] last job submit (parse_set_007) not completed, retry again in 12 sec
[2016-12-06 23:28:37] current cores used: 12/20
[2016-12-06 23:28:37] last job submit (parse_set_007) not completed, retry again in 12 sec
[2016-12-06 23:28:50] current cores used: 12/20
[2016-12-06 23:28:50] last job submit (parse_set_007) not completed, retry again in 12 sec
[2016-12-06 23:28:57] reading file: ericsson_umts_demo/set_007
[2016-12-06 23:29:02] current cores used: 14/20
[2016-12-06 23:29:02] Task parse_set_008 start...
[2016-12-06 23:29:02] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_008 "parse_set_008" "./test" &
[2016-12-06 23:29:16] current cores used: 14/20
[2016-12-06 23:29:16] last job submit (parse_set_008) not completed, retry again in 12 sec
[2016-12-06 23:29:28] current cores used: 14/20
[2016-12-06 23:29:28] last job submit (parse_set_008) not completed, retry again in 12 sec
[2016-12-06 23:29:41] current cores used: 14/20
[2016-12-06 23:29:41] last job submit (parse_set_008) not completed, retry again in 12 sec
[2016-12-06 23:29:36] Job: parse_set_000: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.59): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.59): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

[2016-12-06 23:29:54] current cores used: 14/20
[2016-12-06 23:29:54] last job submit (parse_set_008) not completed, retry again in 12 sec
[2016-12-06 23:29:54] Job: parse_set_004: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.60): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 172, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 167, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 800, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 139, in load_stream
    yield self._read_with_length(stream)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 164, in _read_with_length
    return self.loads(obj)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 422, in loads
    return pickle.loads(obj)
MemoryError

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 172, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 167, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 800, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 139, in load_stream
    yield self._read_with_length(stream)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 164, in _read_with_length
    return self.loads(obj)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 422, in loads
    return pickle.loads(obj)
MemoryError

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.60): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 172, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 167, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 800, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 139, in load_stream
    yield self._read_with_length(stream)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 164, in _read_with_length
    return self.loads(obj)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 422, in loads
    return pickle.loads(obj)
MemoryError

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 172, in main
    process()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/worker.py", line 167, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 800, in func
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 139, in load_stream
    yield self._read_with_length(stream)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 164, in _read_with_length
    return self.loads(obj)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 422, in loads
    return pickle.loads(obj)
MemoryError

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

[2016-12-06 23:29:55] Job: parse_set_006: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.59): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.59): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-06 23:29:56] finish reading file: ericsson_umts_demo/set_007
[2016-12-06 23:30:06] current cores used: 8/20
[2016-12-06 23:30:06] last job submit (parse_set_008) not completed, retry again in 12 sec
[2016-12-06 23:30:13] reading file: ericsson_umts_demo/set_008
[2016-12-06 23:30:18] current cores used: 10/20
[2016-12-06 23:30:18] Task parse_set_009 start...
[2016-12-06 23:30:18] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_009 "parse_set_009" "./test" &
[2016-12-06 23:30:22] finish reading file: ericsson_umts_demo/set_008
[2016-12-06 23:30:27] reading file: ericsson_umts_demo/set_009
[2016-12-06 23:30:30] current cores used: 12/20
[2016-12-06 23:30:30] Task parse_set_010 start...
[2016-12-06 23:30:30] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_010 "parse_set_010" "./test" &
[2016-12-06 23:30:40] finish reading file: ericsson_umts_demo/set_009
[2016-12-06 23:30:42] current cores used: 12/20
[2016-12-06 23:30:42] last job submit (parse_set_010) not completed, retry again in 12 sec
[2016-12-06 23:30:44] start writing file: ./test/set_001.txt
[2016-12-06 23:30:55] current cores used: 14/20
[2016-12-06 23:30:55] Task parse_set_011 start...
[2016-12-06 23:30:55] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_011 "parse_set_011" "./test" &
[2016-12-06 23:31:09] current cores used: 14/20
[2016-12-06 23:31:09] last job submit (parse_set_011) not completed, retry again in 12 sec
[2016-12-06 23:31:12] reading file: ericsson_umts_demo/set_010
[2016-12-06 23:31:21] current cores used: 14/20
[2016-12-06 23:31:21] last job submit (parse_set_011) not completed, retry again in 12 sec
[2016-12-06 23:31:36] current cores used: 14/20
[2016-12-06 23:31:36] last job submit (parse_set_011) not completed, retry again in 12 sec
[2016-12-06 23:31:48] current cores used: 14/20
[2016-12-06 23:31:48] last job submit (parse_set_011) not completed, retry again in 12 sec
[2016-12-06 23:31:51] finish reading file: ericsson_umts_demo/set_010
[2016-12-06 23:32:01] current cores used: 14/20
[2016-12-06 23:32:01] last job submit (parse_set_011) not completed, retry again in 12 sec
[2016-12-06 23:32:13] current cores used: 14/20
[2016-12-06 23:32:13] last job submit (parse_set_011) not completed, retry again in 12 sec
[2016-12-06 23:32:23] reading file: ericsson_umts_demo/set_011
[2016-12-06 23:32:25] current cores used: 16/20
[2016-12-06 23:32:25] Task parse_set_012 start...
[2016-12-06 23:32:25] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_012 "parse_set_012" "./test" &
[2016-12-06 23:32:38] current cores used: 16/20
[2016-12-06 23:32:38] last job submit (parse_set_012) not completed, retry again in 12 sec
[2016-12-06 23:32:50] current cores used: 16/20
[2016-12-06 23:32:50] last job submit (parse_set_012) not completed, retry again in 12 sec
[2016-12-06 23:33:03] current cores used: 16/20
[2016-12-06 23:33:03] last job submit (parse_set_012) not completed, retry again in 12 sec
[2016-12-06 23:33:08] reading file: ericsson_umts_demo/set_012
[2016-12-06 23:33:17] current cores used: 18/20
[2016-12-06 23:33:17] cores close to limit, retry again in 24 sec
[2016-12-06 23:33:44] current cores used: 18/20
[2016-12-06 23:33:44] Task parse_set_013 start...
[2016-12-06 23:33:44] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_013 "parse_set_013" "./test" &
[2016-12-06 23:33:58] current cores used: 18/20
[2016-12-06 23:33:58] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:34:12] current cores used: 18/20
[2016-12-06 23:34:12] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:34:25] current cores used: 18/20
[2016-12-06 23:34:25] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:34:26] finish reading file: ericsson_umts_demo/set_012
[2016-12-06 23:34:37] current cores used: 18/20
[2016-12-06 23:34:37] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:34:57] current cores used: 18/20
[2016-12-06 23:34:57] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:35:10] current cores used: 16/20
[2016-12-06 23:35:10] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:35:22] current cores used: 16/20
[2016-12-06 23:35:22] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:35:37] current cores used: 16/20
[2016-12-06 23:35:37] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:35:42] finish writing file: ./test/set_001.txt
[2016-12-06 23:35:53] current cores used: 18/20
[2016-12-06 23:35:53] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:36:06] current cores used: 18/20
[2016-12-06 23:36:06] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:36:18] current cores used: 16/20
[2016-12-06 23:36:18] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:36:32] current cores used: 16/20
[2016-12-06 23:36:32] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:36:46] current cores used: 16/20
[2016-12-06 23:36:46] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:37:03] current cores used: 16/20
[2016-12-06 23:37:03] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:37:04] Job: parse_set_008: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.59): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.59): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-06 23:37:15] current cores used: 12/20
[2016-12-06 23:37:15] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:37:27] current cores used: 12/20
[2016-12-06 23:37:27] last job submit (parse_set_013) not completed, retry again in 12 sec
[2016-12-06 23:37:33] reading file: ericsson_umts_demo/set_013
[2016-12-06 23:37:39] current cores used: 14/20
[2016-12-06 23:37:39] Task parse_set_014 start...
[2016-12-06 23:37:39] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_014 "parse_set_014" "./test" &
[2016-12-06 23:37:48] finish reading file: ericsson_umts_demo/set_011
[2016-12-06 23:37:50] finish reading file: ericsson_umts_demo/set_013
[2016-12-06 23:37:51] current cores used: 14/20
[2016-12-06 23:37:51] last job submit (parse_set_014) not completed, retry again in 12 sec
[2016-12-06 23:38:03] current cores used: 16/20
[2016-12-06 23:38:03] Task parse_set_015 start...
[2016-12-06 23:38:03] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_015 "parse_set_015" "./test" &
[2016-12-06 23:38:05] reading file: ericsson_umts_demo/set_014
[2016-12-06 23:38:15] reading file: ericsson_umts_demo/set_015
[2016-12-06 23:38:15] current cores used: 18/20
[2016-12-06 23:38:15] cores close to limit, retry again in 24 sec
[2016-12-06 23:38:53] current cores used: 18/20
[2016-12-06 23:38:53] Task parse_set_016 start...
[2016-12-06 23:38:53] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_016 "parse_set_016" "./test" &
[2016-12-06 23:39:13] current cores used: 18/20
[2016-12-06 23:39:13] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:39:25] current cores used: 18/20
[2016-12-06 23:39:25] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:39:26] finish reading file: ericsson_umts_demo/set_014
[2016-12-06 23:39:27] finish reading file: ericsson_umts_demo/set_015
[2016-12-06 23:39:39] current cores used: 18/20
[2016-12-06 23:39:39] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:39:45] Job: parse_set_010: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 7, 10.26.127.60): java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 7, 10.26.127.60): java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

[2016-12-06 23:39:59] current cores used: 18/20
[2016-12-06 23:39:59] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:39:53] Job: parse_set_005: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.59): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
[2016-12-06 23:39:51] Job: parse_set_007: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.60): java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.60): java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.59): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-06 23:40:14] current cores used: 18/20
[2016-12-06 23:40:14] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:40:27] current cores used: 18/20
[2016-12-06 23:40:27] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:40:39] current cores used: 18/20
[2016-12-06 23:40:39] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:40:51] current cores used: 16/20
[2016-12-06 23:40:51] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:41:04] current cores used: 14/20
[2016-12-06 23:41:04] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:41:16] current cores used: 12/20
[2016-12-06 23:41:16] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:41:28] current cores used: 12/20
[2016-12-06 23:41:28] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:41:40] current cores used: 12/20
[2016-12-06 23:41:40] last job submit (parse_set_016) not completed, retry again in 12 sec
[2016-12-06 23:41:45] reading file: ericsson_umts_demo/set_016
[2016-12-06 23:41:52] current cores used: 14/20
[2016-12-06 23:41:52] Task parse_set_017 start...
[2016-12-06 23:41:52] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_017 "parse_set_017" "./test" &
[2016-12-06 23:42:04] Job: parse_set_013: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 6, 10.26.127.58): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 6, 10.26.127.58): ExecutorLostFailure (executor 3 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-06 23:42:04] current cores used: 14/20
[2016-12-06 23:42:04] last job submit (parse_set_017) not completed, retry again in 12 sec
Exception in thread Thread-1 (most likely raised during interpreter shutdown):
Traceback (most recent call last):
  File "/usr/lib64/python2.7/threading.py", line 811, in __bootstrap_inner
  File "/usr/lib64/python2.7/threading.py", line 764, in run
  File "/usr/lib64/python2.7/SocketServer.py", line 241, in serve_forever
  File "/usr/lib64/python2.7/threading.py", line 586, in set
  File "/usr/lib64/python2.7/threading.py", line 409, in notifyAll
<type 'exceptions.TypeError'>: 'NoneType' object is not callable
[2016-12-06 23:42:09] finish reading file: ericsson_umts_demo/set_016
[2016-12-06 23:42:09] reading file: ericsson_umts_demo/set_017
[2016-12-06 23:42:17] current cores used: 14/20
[2016-12-06 23:42:17] Task parse_set_018 start...
[2016-12-06 23:42:17] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_018 "parse_set_018" "./test" &
[2016-12-06 23:42:21] finish reading file: ericsson_umts_demo/set_017
[2016-12-06 23:42:29] current cores used: 16/20
[2016-12-06 23:42:29] Task parse_set_019 start...
[2016-12-06 23:42:29] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_019 "parse_set_019" "./test" &
[2016-12-06 23:42:30] reading file: ericsson_umts_demo/set_018
[2016-12-06 23:42:41] current cores used: 16/20
[2016-12-06 23:42:41] last job submit (parse_set_019) not completed, retry again in 12 sec
[2016-12-06 23:42:45] reading file: ericsson_umts_demo/set_019
[2016-12-06 23:42:56] current cores used: 18/20
[2016-12-06 23:42:57] cores close to limit, retry again in 24 sec
[2016-12-06 23:43:28] current cores used: 18/20
[2016-12-06 23:43:28] Task parse_set_020 start...
[2016-12-06 23:43:28] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_020 "parse_set_020" "./test" &
[2016-12-06 23:43:20] Job: parse_set_015: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 6, 10.26.127.58): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 6, 10.26.127.58): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

[2016-12-06 23:43:55] finish reading file: ericsson_umts_demo/set_018
[2016-12-06 23:44:05] current cores used: 18/20
[2016-12-06 23:44:05] last job submit (parse_set_020) not completed, retry again in 12 sec
[2016-12-06 23:44:20] current cores used: 16/20
[2016-12-06 23:44:20] last job submit (parse_set_020) not completed, retry again in 12 sec
[2016-12-06 23:44:33] current cores used: 16/20
[2016-12-06 23:44:33] last job submit (parse_set_020) not completed, retry again in 12 sec
[2016-12-06 23:44:45] current cores used: 16/20
[2016-12-06 23:44:45] last job submit (parse_set_020) not completed, retry again in 12 sec
[2016-12-06 23:44:57] current cores used: 16/20
[2016-12-06 23:44:57] last job submit (parse_set_020) not completed, retry again in 12 sec
[2016-12-06 23:45:07] finish reading file: ericsson_umts_demo/set_019
[2016-12-06 23:45:09] current cores used: 16/20
[2016-12-06 23:45:09] last job submit (parse_set_020) not completed, retry again in 12 sec
[2016-12-06 23:45:21] current cores used: 16/20
[2016-12-06 23:45:21] last job submit (parse_set_020) not completed, retry again in 12 sec
[2016-12-06 23:45:34] current cores used: 18/20
[2016-12-06 23:45:34] cores close to limit, retry again in 24 sec
[2016-12-06 23:45:48] Job: parse_set_016: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.58): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.58): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-06 23:45:59] current cores used: 18/20
[2016-12-06 23:45:59] Task parse_set_021 start...
[2016-12-06 23:45:59] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_021 "parse_set_021" "./test" &
[2016-12-06 23:46:18] current cores used: 16/20
[2016-12-06 23:46:18] last job submit (parse_set_021) not completed, retry again in 12 sec
[2016-12-06 23:46:32] current cores used: 16/20
[2016-12-06 23:46:32] last job submit (parse_set_021) not completed, retry again in 12 sec
[2016-12-06 23:46:36] reading file: ericsson_umts_demo/set_020
[2016-12-06 23:46:44] current cores used: 16/20
[2016-12-06 23:46:44] last job submit (parse_set_021) not completed, retry again in 12 sec
[2016-12-06 23:46:57] current cores used: 16/20
[2016-12-06 23:46:57] last job submit (parse_set_021) not completed, retry again in 12 sec
[2016-12-06 23:47:09] current cores used: 16/20
[2016-12-06 23:47:09] last job submit (parse_set_021) not completed, retry again in 12 sec
[2016-12-06 23:47:09] finish reading file: ericsson_umts_demo/set_020
[2016-12-06 23:47:21] current cores used: 18/20
[2016-12-06 23:47:21] cores close to limit, retry again in 24 sec
[2016-12-06 23:47:21] reading file: ericsson_umts_demo/set_021
[2016-12-06 23:47:30] Job: parse_set_019: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 7, 10.26.127.58): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 7, 10.26.127.58): ExecutorLostFailure (executor 1 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-06 23:47:43] finish reading file: ericsson_umts_demo/set_021
[2016-12-06 23:47:45] current cores used: 16/20
[2016-12-06 23:47:45] Task parse_set_022 start...
[2016-12-06 23:47:45] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_022 "parse_set_022" "./test" &
[2016-12-06 23:47:49] Job: parse_set_014: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.60): java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 5, 10.26.127.60): java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Connection reset
	at java.net.SocketInputStream.read(SocketInputStream.java:209)
	at java.net.SocketInputStream.read(SocketInputStream.java:141)
	at java.io.BufferedInputStream.fill(BufferedInputStream.java:246)
	at java.io.BufferedInputStream.read(BufferedInputStream.java:265)
	at java.io.DataInputStream.readInt(DataInputStream.java:387)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more

[2016-12-06 23:47:55] Job: parse_set_018: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 7, 10.26.127.58): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 7, 10.26.127.58): ExecutorLostFailure (executor 2 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-06 23:47:58] current cores used: 12/20
[2016-12-06 23:47:58] last job submit (parse_set_022) not completed, retry again in 12 sec
[2016-12-06 23:48:10] current cores used: 12/20
[2016-12-06 23:48:10] last job submit (parse_set_022) not completed, retry again in 12 sec
[2016-12-06 23:48:18] reading file: ericsson_umts_demo/set_022
[2016-12-06 23:48:22] current cores used: 14/20
[2016-12-06 23:48:22] Task parse_set_023 start...
[2016-12-06 23:48:22] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_023 "parse_set_023" "./test" &
[2016-12-06 23:48:29] finish reading file: ericsson_umts_demo/set_022
[2016-12-06 23:48:33] reading file: ericsson_umts_demo/set_023
[2016-12-06 23:48:34] current cores used: 16/20
[2016-12-06 23:48:34] Task parse_set_024 start...
[2016-12-06 23:48:34] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_024 "parse_set_024" "./test" &
[2016-12-06 23:48:46] current cores used: 18/20
[2016-12-06 23:48:46] cores close to limit, retry again in 24 sec
[2016-12-06 23:48:48] reading file: ericsson_umts_demo/set_024
[2016-12-06 23:48:49] finish reading file: ericsson_umts_demo/set_023
[2016-12-06 23:49:11] current cores used: 18/20
[2016-12-06 23:49:11] Task parse_set_025 start...
[2016-12-06 23:49:11] spark-submit --master spark://master:7077 --executor-memory 1g --driver-memory 512m --total-executor-cores 2 /opt/hadoop/wwong/eric_umts/kpi_parser_eric.py ericsson_umts_demo/set_025 "parse_set_025" "./test" &
[2016-12-06 23:49:27] current cores used: 18/20
[2016-12-06 23:49:27] last job submit (parse_set_025) not completed, retry again in 12 sec
#
# There is insufficient memory for the Java Runtime Environment to continue.
# Native memory allocation (mmap) failed to map 88080384 bytes for committing reserved memory.
# An error report file with more information is saved as:
# /opt/hadoop/wwong/eric_umts/output/hs_err_pid59569.log
[2016-12-06 23:49:39] current cores used: 18/20
[2016-12-06 23:49:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:49:50] Job: parse_set_022: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 7, 10.26.127.58): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
[2016-12-06 23:49:52] current cores used: 18/20
[2016-12-06 23:49:52] last job submit (parse_set_025) not completed, retry again in 12 sec
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 7, 10.26.127.58): ExecutorLostFailure (executor 5 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-06 23:50:02] finish reading file: ericsson_umts_demo/set_024
[2016-12-06 23:50:04] current cores used: 16/20
[2016-12-06 23:50:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:50:16] current cores used: 16/20
[2016-12-06 23:50:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:50:28] current cores used: 16/20
[2016-12-06 23:50:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:50:40] current cores used: 16/20
[2016-12-06 23:50:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:50:52] Job: parse_set_020: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 6, 10.26.127.58): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 6, 10.26.127.58): java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.net.SocketException: Broken pipe (Write failed)
	at java.net.SocketOutputStream.socketWrite0(Native Method)
	at java.net.SocketOutputStream.socketWrite(SocketOutputStream.java:109)
	at java.net.SocketOutputStream.write(SocketOutputStream.java:153)
	at java.io.BufferedOutputStream.write(BufferedOutputStream.java:122)
	at java.io.DataOutputStream.write(DataOutputStream.java:107)
	at java.io.FilterOutputStream.write(FilterOutputStream.java:97)
	at org.apache.spark.api.python.PythonRDD$.org$apache$spark$api$python$PythonRDD$$write$1(PythonRDD.scala:492)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRDD$$anonfun$writeIteratorToStream$1.apply(PythonRDD.scala:504)
	at scala.collection.Iterator$class.foreach(Iterator.scala:893)
	at org.apache.spark.api.python.SerDeUtil$AutoBatchedPickler.foreach(SerDeUtil.scala:112)
	at org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:504)
	at org.apache.spark.api.python.PythonRunner$WriterThread$$anonfun$run$3.apply(PythonRDD.scala:328)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1857)
	at org.apache.spark.api.python.PythonRunner$WriterThread.run(PythonRDD.scala:269)

[2016-12-06 23:50:52] current cores used: 16/20
[2016-12-06 23:50:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:51:04] current cores used: 14/20
[2016-12-06 23:51:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:51:16] current cores used: 14/20
[2016-12-06 23:51:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:51:28] current cores used: 14/20
[2016-12-06 23:51:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:51:41] current cores used: 14/20
[2016-12-06 23:51:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:51:53] current cores used: 14/20
[2016-12-06 23:51:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:52:05] current cores used: 14/20
[2016-12-06 23:52:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:52:17] current cores used: 14/20
[2016-12-06 23:52:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:52:29] current cores used: 14/20
[2016-12-06 23:52:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:52:35] Job: parse_set_009: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.52): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 4 times, most recent failure: Lost task 0.3 in stage 1.0 (TID 5, 10.26.127.52): ExecutorLostFailure (executor 4 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-06 23:52:41] current cores used: 14/20
[2016-12-06 23:52:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:52:53] current cores used: 12/20
[2016-12-06 23:52:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:53:06] current cores used: 12/20
[2016-12-06 23:53:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:53:18] current cores used: 12/20
[2016-12-06 23:53:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:53:30] current cores used: 12/20
[2016-12-06 23:53:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:53:42] current cores used: 12/20
[2016-12-06 23:53:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:53:54] current cores used: 12/20
[2016-12-06 23:53:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:54:06] current cores used: 12/20
[2016-12-06 23:54:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:54:18] current cores used: 12/20
[2016-12-06 23:54:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:54:30] current cores used: 12/20
[2016-12-06 23:54:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:54:42] current cores used: 12/20
[2016-12-06 23:54:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:54:55] current cores used: 12/20
[2016-12-06 23:54:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:55:07] current cores used: 12/20
[2016-12-06 23:55:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:55:13] Job: parse_set_021: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 6, 10.26.127.59): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 6, 10.26.127.59): ExecutorLostFailure (executor 0 exited caused by one of the running tasks) Reason: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)

[2016-12-06 23:55:19] current cores used: 10/20
[2016-12-06 23:55:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:55:31] current cores used: 10/20
[2016-12-06 23:55:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:55:42] start writing file: ./test/set_024.txt
[2016-12-06 23:55:43] current cores used: 10/20
[2016-12-06 23:55:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:55:55] current cores used: 10/20
[2016-12-06 23:55:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:56:07] current cores used: 10/20
[2016-12-06 23:56:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:56:19] current cores used: 10/20
[2016-12-06 23:56:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:56:31] current cores used: 10/20
[2016-12-06 23:56:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:56:43] current cores used: 10/20
[2016-12-06 23:56:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:56:55] current cores used: 10/20
[2016-12-06 23:56:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:57:07] finish writing file: ./test/set_024.txt
[2016-12-06 23:57:07] current cores used: 10/20
[2016-12-06 23:57:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:57:19] current cores used: 8/20
[2016-12-06 23:57:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:57:31] current cores used: 8/20
[2016-12-06 23:57:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:57:44] current cores used: 8/20
[2016-12-06 23:57:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:57:56] current cores used: 8/20
[2016-12-06 23:57:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:58:08] current cores used: 8/20
[2016-12-06 23:58:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:58:20] current cores used: 8/20
[2016-12-06 23:58:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:58:32] current cores used: 8/20
[2016-12-06 23:58:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:58:44] current cores used: 8/20
[2016-12-06 23:58:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:58:56] current cores used: 8/20
[2016-12-06 23:58:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:59:08] current cores used: 8/20
[2016-12-06 23:59:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:59:20] current cores used: 8/20
[2016-12-06 23:59:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:59:32] current cores used: 8/20
[2016-12-06 23:59:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:59:44] current cores used: 8/20
[2016-12-06 23:59:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-06 23:59:56] current cores used: 8/20
[2016-12-06 23:59:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:00:08] current cores used: 8/20
[2016-12-07 00:00:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:00:20] current cores used: 8/20
[2016-12-07 00:00:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:00:32] current cores used: 8/20
[2016-12-07 00:00:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:00:44] current cores used: 8/20
[2016-12-07 00:00:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:00:56] current cores used: 8/20
[2016-12-07 00:00:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:01:09] current cores used: 8/20
[2016-12-07 00:01:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:01:21] current cores used: 8/20
[2016-12-07 00:01:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:01:33] current cores used: 8/20
[2016-12-07 00:01:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:01:45] current cores used: 8/20
[2016-12-07 00:01:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:01:57] current cores used: 8/20
[2016-12-07 00:01:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:02:09] current cores used: 8/20
[2016-12-07 00:02:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:02:21] current cores used: 8/20
[2016-12-07 00:02:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:02:33] current cores used: 8/20
[2016-12-07 00:02:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:02:45] current cores used: 8/20
[2016-12-07 00:02:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:02:57] current cores used: 8/20
[2016-12-07 00:02:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:03:09] current cores used: 8/20
[2016-12-07 00:03:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:03:21] current cores used: 8/20
[2016-12-07 00:03:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:03:33] current cores used: 8/20
[2016-12-07 00:03:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:03:45] current cores used: 8/20
[2016-12-07 00:03:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:03:57] current cores used: 8/20
[2016-12-07 00:03:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:04:09] current cores used: 8/20
[2016-12-07 00:04:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:04:21] current cores used: 8/20
[2016-12-07 00:04:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:04:33] current cores used: 8/20
[2016-12-07 00:04:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:04:45] current cores used: 8/20
[2016-12-07 00:04:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:04:57] current cores used: 8/20
[2016-12-07 00:04:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:05:09] current cores used: 8/20
[2016-12-07 00:05:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:05:21] Job: parse_set_002: Other Exception Error: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 8, 10.26.127.52): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:230)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	... 11 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:230)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	... 11 more
!
Traceback (most recent call last):
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 268, in <module>
    main(sc, filename)
  File "/opt/hadoop/wwong/eric_umts/kpi_parser_eric.py", line 136, in main
    redRDD = mapRDD.reduce(f_reduce)
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 802, in reduce
    vals = self.mapPartitions(func).collect()
  File "/opt/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 776, in collect
    port = self.ctx._jvm.PythonRDD.collectAndServe(self._jrdd.rdd())
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    
  File "/opt/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.collectAndServe.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 1.0 failed 4 times, most recent failure: Lost task 1.3 in stage 1.0 (TID 8, 10.26.127.52): org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:230)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	... 11 more

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1911)
	at org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:893)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:358)
	at org.apache.spark.rdd.RDD.collect(RDD.scala:892)
	at org.apache.spark.api.python.PythonRDD$.collectAndServe(PythonRDD.scala:453)
	at org.apache.spark.api.python.PythonRDD.collectAndServe(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.SparkException: Python worker exited unexpectedly (crashed)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:230)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:166)
	... 11 more

[2016-12-07 00:05:21] current cores used: 8/20
[2016-12-07 00:05:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:05:33] current cores used: 6/20
[2016-12-07 00:05:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:05:42] start writing file: ./test/set_023.txt
[2016-12-07 00:05:46] current cores used: 6/20
[2016-12-07 00:05:46] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:05:58] current cores used: 6/20
[2016-12-07 00:05:58] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:06:10] current cores used: 6/20
[2016-12-07 00:06:10] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:06:22] current cores used: 6/20
[2016-12-07 00:06:22] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:06:34] current cores used: 6/20
[2016-12-07 00:06:34] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:06:46] current cores used: 6/20
[2016-12-07 00:06:46] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:06:53] finish writing file: ./test/set_023.txt
[2016-12-07 00:06:58] current cores used: 4/20
[2016-12-07 00:06:58] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:07:10] current cores used: 4/20
[2016-12-07 00:07:10] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:07:22] current cores used: 4/20
[2016-12-07 00:07:22] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:07:35] current cores used: 4/20
[2016-12-07 00:07:35] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:07:47] current cores used: 4/20
[2016-12-07 00:07:47] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:07:59] current cores used: 4/20
[2016-12-07 00:07:59] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:08:11] current cores used: 4/20
[2016-12-07 00:08:11] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:08:23] current cores used: 4/20
[2016-12-07 00:08:23] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:08:35] current cores used: 4/20
[2016-12-07 00:08:35] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:08:48] current cores used: 4/20
[2016-12-07 00:08:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:09:00] current cores used: 4/20
[2016-12-07 00:09:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:09:12] current cores used: 4/20
[2016-12-07 00:09:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:09:24] current cores used: 4/20
[2016-12-07 00:09:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:09:36] current cores used: 4/20
[2016-12-07 00:09:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:09:48] current cores used: 4/20
[2016-12-07 00:09:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:10:00] current cores used: 4/20
[2016-12-07 00:10:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:10:12] current cores used: 4/20
[2016-12-07 00:10:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:10:24] current cores used: 4/20
[2016-12-07 00:10:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:10:36] current cores used: 4/20
[2016-12-07 00:10:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:10:48] current cores used: 4/20
[2016-12-07 00:10:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:11:00] current cores used: 4/20
[2016-12-07 00:11:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:11:12] current cores used: 4/20
[2016-12-07 00:11:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:11:24] current cores used: 4/20
[2016-12-07 00:11:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:11:36] current cores used: 4/20
[2016-12-07 00:11:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:11:48] current cores used: 4/20
[2016-12-07 00:11:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:12:00] current cores used: 4/20
[2016-12-07 00:12:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:12:12] current cores used: 4/20
[2016-12-07 00:12:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:12:24] current cores used: 4/20
[2016-12-07 00:12:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:12:36] current cores used: 4/20
[2016-12-07 00:12:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:12:48] current cores used: 4/20
[2016-12-07 00:12:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:13:00] current cores used: 4/20
[2016-12-07 00:13:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:13:11] start writing file: ./test/set_011.txt
[2016-12-07 00:13:12] current cores used: 4/20
[2016-12-07 00:13:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:13:24] current cores used: 4/20
[2016-12-07 00:13:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:13:36] current cores used: 4/20
[2016-12-07 00:13:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:13:48] current cores used: 4/20
[2016-12-07 00:13:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:14:00] current cores used: 4/20
[2016-12-07 00:14:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:14:12] current cores used: 4/20
[2016-12-07 00:14:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:14:23] finish writing file: ./test/set_011.txt
[2016-12-07 00:14:24] current cores used: 2/20
[2016-12-07 00:14:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:14:36] current cores used: 2/20
[2016-12-07 00:14:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:14:48] current cores used: 2/20
[2016-12-07 00:14:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:15:00] current cores used: 2/20
[2016-12-07 00:15:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:15:13] current cores used: 2/20
[2016-12-07 00:15:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:15:25] current cores used: 2/20
[2016-12-07 00:15:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:15:37] current cores used: 2/20
[2016-12-07 00:15:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:15:49] current cores used: 2/20
[2016-12-07 00:15:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:16:01] current cores used: 2/20
[2016-12-07 00:16:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:16:13] current cores used: 2/20
[2016-12-07 00:16:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:16:25] current cores used: 2/20
[2016-12-07 00:16:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:16:37] current cores used: 2/20
[2016-12-07 00:16:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:16:47] start writing file: ./test/set_017.txt
[2016-12-07 00:16:49] current cores used: 2/20
[2016-12-07 00:16:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:17:01] current cores used: 2/20
[2016-12-07 00:17:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:17:13] current cores used: 2/20
[2016-12-07 00:17:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:17:25] current cores used: 2/20
[2016-12-07 00:17:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:17:37] current cores used: 2/20
[2016-12-07 00:17:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:17:49] current cores used: 2/20
[2016-12-07 00:17:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:18:01] current cores used: 2/20
[2016-12-07 00:18:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:18:02] finish writing file: ./test/set_017.txt
[2016-12-07 00:18:13] current cores used: 0/20
[2016-12-07 00:18:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:18:25] current cores used: 0/20
[2016-12-07 00:18:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:18:37] current cores used: 0/20
[2016-12-07 00:18:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:18:49] current cores used: 0/20
[2016-12-07 00:18:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:19:01] current cores used: 0/20
[2016-12-07 00:19:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:19:13] current cores used: 0/20
[2016-12-07 00:19:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:19:25] current cores used: 0/20
[2016-12-07 00:19:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:19:37] current cores used: 0/20
[2016-12-07 00:19:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:19:49] current cores used: 0/20
[2016-12-07 00:19:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:20:01] current cores used: 0/20
[2016-12-07 00:20:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:20:13] current cores used: 0/20
[2016-12-07 00:20:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:20:25] current cores used: 0/20
[2016-12-07 00:20:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:20:37] current cores used: 0/20
[2016-12-07 00:20:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:20:49] current cores used: 0/20
[2016-12-07 00:20:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:21:02] current cores used: 0/20
[2016-12-07 00:21:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:21:14] current cores used: 0/20
[2016-12-07 00:21:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:21:26] current cores used: 0/20
[2016-12-07 00:21:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:21:38] current cores used: 0/20
[2016-12-07 00:21:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:21:50] current cores used: 0/20
[2016-12-07 00:21:50] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:22:02] current cores used: 0/20
[2016-12-07 00:22:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:22:14] current cores used: 0/20
[2016-12-07 00:22:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:22:26] current cores used: 0/20
[2016-12-07 00:22:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:22:38] current cores used: 0/20
[2016-12-07 00:22:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:22:50] current cores used: 0/20
[2016-12-07 00:22:50] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:23:02] current cores used: 0/20
[2016-12-07 00:23:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:23:14] current cores used: 0/20
[2016-12-07 00:23:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:23:26] current cores used: 0/20
[2016-12-07 00:23:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:23:38] current cores used: 0/20
[2016-12-07 00:23:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:23:50] current cores used: 0/20
[2016-12-07 00:23:50] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:24:02] current cores used: 0/20
[2016-12-07 00:24:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:24:14] current cores used: 0/20
[2016-12-07 00:24:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:24:26] current cores used: 0/20
[2016-12-07 00:24:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:24:38] current cores used: 0/20
[2016-12-07 00:24:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:24:50] current cores used: 0/20
[2016-12-07 00:24:50] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:25:02] current cores used: 0/20
[2016-12-07 00:25:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:25:14] current cores used: 0/20
[2016-12-07 00:25:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:25:26] current cores used: 0/20
[2016-12-07 00:25:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:25:38] current cores used: 0/20
[2016-12-07 00:25:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:25:51] current cores used: 0/20
[2016-12-07 00:25:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:26:03] current cores used: 0/20
[2016-12-07 00:26:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:26:15] current cores used: 0/20
[2016-12-07 00:26:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:26:27] current cores used: 0/20
[2016-12-07 00:26:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:26:39] current cores used: 0/20
[2016-12-07 00:26:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:26:51] current cores used: 0/20
[2016-12-07 00:26:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:27:03] current cores used: 0/20
[2016-12-07 00:27:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:27:15] current cores used: 0/20
[2016-12-07 00:27:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:27:27] current cores used: 0/20
[2016-12-07 00:27:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:27:39] current cores used: 0/20
[2016-12-07 00:27:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:27:51] current cores used: 0/20
[2016-12-07 00:27:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:28:03] current cores used: 0/20
[2016-12-07 00:28:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:28:15] current cores used: 0/20
[2016-12-07 00:28:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:28:27] current cores used: 0/20
[2016-12-07 00:28:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:28:39] current cores used: 0/20
[2016-12-07 00:28:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:28:51] current cores used: 0/20
[2016-12-07 00:28:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:29:03] current cores used: 0/20
[2016-12-07 00:29:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:29:15] current cores used: 0/20
[2016-12-07 00:29:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:29:27] current cores used: 0/20
[2016-12-07 00:29:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:29:39] current cores used: 0/20
[2016-12-07 00:29:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:29:51] current cores used: 0/20
[2016-12-07 00:29:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:30:03] current cores used: 0/20
[2016-12-07 00:30:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:30:15] current cores used: 0/20
[2016-12-07 00:30:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:30:27] current cores used: 0/20
[2016-12-07 00:30:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:30:39] current cores used: 0/20
[2016-12-07 00:30:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:30:51] current cores used: 0/20
[2016-12-07 00:30:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:31:03] current cores used: 0/20
[2016-12-07 00:31:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:31:15] current cores used: 0/20
[2016-12-07 00:31:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:31:27] current cores used: 0/20
[2016-12-07 00:31:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:31:39] current cores used: 0/20
[2016-12-07 00:31:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:31:51] current cores used: 0/20
[2016-12-07 00:31:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:32:04] current cores used: 0/20
[2016-12-07 00:32:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:32:16] current cores used: 0/20
[2016-12-07 00:32:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:32:28] current cores used: 0/20
[2016-12-07 00:32:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:32:40] current cores used: 0/20
[2016-12-07 00:32:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:32:52] current cores used: 0/20
[2016-12-07 00:32:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:33:04] current cores used: 0/20
[2016-12-07 00:33:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:33:16] current cores used: 0/20
[2016-12-07 00:33:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:33:28] current cores used: 0/20
[2016-12-07 00:33:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:33:40] current cores used: 0/20
[2016-12-07 00:33:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:33:52] current cores used: 0/20
[2016-12-07 00:33:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:34:04] current cores used: 0/20
[2016-12-07 00:34:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:34:16] current cores used: 0/20
[2016-12-07 00:34:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:34:28] current cores used: 0/20
[2016-12-07 00:34:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:34:40] current cores used: 0/20
[2016-12-07 00:34:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:34:52] current cores used: 0/20
[2016-12-07 00:34:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:35:04] current cores used: 0/20
[2016-12-07 00:35:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:35:16] current cores used: 0/20
[2016-12-07 00:35:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:35:28] current cores used: 0/20
[2016-12-07 00:35:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:35:40] current cores used: 0/20
[2016-12-07 00:35:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:35:52] current cores used: 0/20
[2016-12-07 00:35:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:36:04] current cores used: 0/20
[2016-12-07 00:36:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:36:16] current cores used: 0/20
[2016-12-07 00:36:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:36:28] current cores used: 0/20
[2016-12-07 00:36:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:36:40] current cores used: 0/20
[2016-12-07 00:36:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:36:52] current cores used: 0/20
[2016-12-07 00:36:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:37:04] current cores used: 0/20
[2016-12-07 00:37:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:37:16] current cores used: 0/20
[2016-12-07 00:37:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:37:28] current cores used: 0/20
[2016-12-07 00:37:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:37:40] current cores used: 0/20
[2016-12-07 00:37:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:37:53] current cores used: 0/20
[2016-12-07 00:37:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:38:05] current cores used: 0/20
[2016-12-07 00:38:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:38:17] current cores used: 0/20
[2016-12-07 00:38:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:38:29] current cores used: 0/20
[2016-12-07 00:38:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:38:41] current cores used: 0/20
[2016-12-07 00:38:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:38:53] current cores used: 0/20
[2016-12-07 00:38:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:39:05] current cores used: 0/20
[2016-12-07 00:39:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:39:17] current cores used: 0/20
[2016-12-07 00:39:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:39:29] current cores used: 0/20
[2016-12-07 00:39:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:39:41] current cores used: 0/20
[2016-12-07 00:39:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:39:53] current cores used: 0/20
[2016-12-07 00:39:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:40:05] current cores used: 0/20
[2016-12-07 00:40:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:40:17] current cores used: 0/20
[2016-12-07 00:40:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:40:29] current cores used: 0/20
[2016-12-07 00:40:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:40:41] current cores used: 0/20
[2016-12-07 00:40:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:40:53] current cores used: 0/20
[2016-12-07 00:40:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:41:05] current cores used: 0/20
[2016-12-07 00:41:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:41:17] current cores used: 0/20
[2016-12-07 00:41:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:41:29] current cores used: 0/20
[2016-12-07 00:41:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:41:41] current cores used: 0/20
[2016-12-07 00:41:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:41:53] current cores used: 0/20
[2016-12-07 00:41:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:42:05] current cores used: 0/20
[2016-12-07 00:42:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:42:17] current cores used: 0/20
[2016-12-07 00:42:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:42:29] current cores used: 0/20
[2016-12-07 00:42:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:42:41] current cores used: 0/20
[2016-12-07 00:42:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:42:53] current cores used: 0/20
[2016-12-07 00:42:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:43:05] current cores used: 0/20
[2016-12-07 00:43:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:43:17] current cores used: 0/20
[2016-12-07 00:43:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:43:30] current cores used: 0/20
[2016-12-07 00:43:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:43:42] current cores used: 0/20
[2016-12-07 00:43:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:43:54] current cores used: 0/20
[2016-12-07 00:43:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:44:06] current cores used: 0/20
[2016-12-07 00:44:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:44:18] current cores used: 0/20
[2016-12-07 00:44:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:44:30] current cores used: 0/20
[2016-12-07 00:44:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:44:42] current cores used: 0/20
[2016-12-07 00:44:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:44:54] current cores used: 0/20
[2016-12-07 00:44:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:45:06] current cores used: 0/20
[2016-12-07 00:45:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:45:18] current cores used: 0/20
[2016-12-07 00:45:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:45:30] current cores used: 0/20
[2016-12-07 00:45:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:45:42] current cores used: 0/20
[2016-12-07 00:45:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:45:54] current cores used: 0/20
[2016-12-07 00:45:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:46:06] current cores used: 0/20
[2016-12-07 00:46:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:46:18] current cores used: 0/20
[2016-12-07 00:46:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:46:30] current cores used: 0/20
[2016-12-07 00:46:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:46:42] current cores used: 0/20
[2016-12-07 00:46:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:46:54] current cores used: 0/20
[2016-12-07 00:46:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:47:06] current cores used: 0/20
[2016-12-07 00:47:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:47:18] current cores used: 0/20
[2016-12-07 00:47:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:47:30] current cores used: 0/20
[2016-12-07 00:47:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:47:42] current cores used: 0/20
[2016-12-07 00:47:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:47:54] current cores used: 0/20
[2016-12-07 00:47:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:48:06] current cores used: 0/20
[2016-12-07 00:48:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:48:18] current cores used: 0/20
[2016-12-07 00:48:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:48:30] current cores used: 0/20
[2016-12-07 00:48:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:48:42] current cores used: 0/20
[2016-12-07 00:48:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:48:54] current cores used: 0/20
[2016-12-07 00:48:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:49:06] current cores used: 0/20
[2016-12-07 00:49:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:49:19] current cores used: 0/20
[2016-12-07 00:49:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:49:31] current cores used: 0/20
[2016-12-07 00:49:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:49:43] current cores used: 0/20
[2016-12-07 00:49:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:49:55] current cores used: 0/20
[2016-12-07 00:49:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:50:07] current cores used: 0/20
[2016-12-07 00:50:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:50:19] current cores used: 0/20
[2016-12-07 00:50:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:50:31] current cores used: 0/20
[2016-12-07 00:50:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:50:43] current cores used: 0/20
[2016-12-07 00:50:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:50:55] current cores used: 0/20
[2016-12-07 00:50:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:51:07] current cores used: 0/20
[2016-12-07 00:51:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:51:19] current cores used: 0/20
[2016-12-07 00:51:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:51:31] current cores used: 0/20
[2016-12-07 00:51:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:51:43] current cores used: 0/20
[2016-12-07 00:51:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:51:55] current cores used: 0/20
[2016-12-07 00:51:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:52:07] current cores used: 0/20
[2016-12-07 00:52:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:52:19] current cores used: 0/20
[2016-12-07 00:52:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:52:31] current cores used: 0/20
[2016-12-07 00:52:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:52:43] current cores used: 0/20
[2016-12-07 00:52:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:52:55] current cores used: 0/20
[2016-12-07 00:52:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:53:07] current cores used: 0/20
[2016-12-07 00:53:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:53:19] current cores used: 0/20
[2016-12-07 00:53:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:53:31] current cores used: 0/20
[2016-12-07 00:53:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:53:43] current cores used: 0/20
[2016-12-07 00:53:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:53:55] current cores used: 0/20
[2016-12-07 00:53:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:54:07] current cores used: 0/20
[2016-12-07 00:54:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:54:19] current cores used: 0/20
[2016-12-07 00:54:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:54:31] current cores used: 0/20
[2016-12-07 00:54:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:54:43] current cores used: 0/20
[2016-12-07 00:54:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:54:55] current cores used: 0/20
[2016-12-07 00:54:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:55:07] current cores used: 0/20
[2016-12-07 00:55:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:55:20] current cores used: 0/20
[2016-12-07 00:55:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:55:32] current cores used: 0/20
[2016-12-07 00:55:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:55:44] current cores used: 0/20
[2016-12-07 00:55:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:55:56] current cores used: 0/20
[2016-12-07 00:55:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:56:08] current cores used: 0/20
[2016-12-07 00:56:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:56:20] current cores used: 0/20
[2016-12-07 00:56:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:56:32] current cores used: 0/20
[2016-12-07 00:56:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:56:44] current cores used: 0/20
[2016-12-07 00:56:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:56:56] current cores used: 0/20
[2016-12-07 00:56:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:57:08] current cores used: 0/20
[2016-12-07 00:57:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:57:20] current cores used: 0/20
[2016-12-07 00:57:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:57:32] current cores used: 0/20
[2016-12-07 00:57:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:57:44] current cores used: 0/20
[2016-12-07 00:57:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:57:56] current cores used: 0/20
[2016-12-07 00:57:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:58:08] current cores used: 0/20
[2016-12-07 00:58:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:58:20] current cores used: 0/20
[2016-12-07 00:58:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:58:32] current cores used: 0/20
[2016-12-07 00:58:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:58:44] current cores used: 0/20
[2016-12-07 00:58:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:58:56] current cores used: 0/20
[2016-12-07 00:58:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:59:08] current cores used: 0/20
[2016-12-07 00:59:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:59:20] current cores used: 0/20
[2016-12-07 00:59:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:59:32] current cores used: 0/20
[2016-12-07 00:59:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:59:44] current cores used: 0/20
[2016-12-07 00:59:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 00:59:56] current cores used: 0/20
[2016-12-07 00:59:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:00:08] current cores used: 0/20
[2016-12-07 01:00:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:00:20] current cores used: 0/20
[2016-12-07 01:00:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:00:32] current cores used: 0/20
[2016-12-07 01:00:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:00:44] current cores used: 0/20
[2016-12-07 01:00:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:00:56] current cores used: 0/20
[2016-12-07 01:00:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:01:08] current cores used: 0/20
[2016-12-07 01:01:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:01:21] current cores used: 0/20
[2016-12-07 01:01:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:01:33] current cores used: 0/20
[2016-12-07 01:01:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:01:45] current cores used: 0/20
[2016-12-07 01:01:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:01:57] current cores used: 0/20
[2016-12-07 01:01:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:02:09] current cores used: 0/20
[2016-12-07 01:02:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:02:21] current cores used: 0/20
[2016-12-07 01:02:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:02:33] current cores used: 0/20
[2016-12-07 01:02:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:02:45] current cores used: 0/20
[2016-12-07 01:02:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:02:57] current cores used: 0/20
[2016-12-07 01:02:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:03:09] current cores used: 0/20
[2016-12-07 01:03:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:03:21] current cores used: 0/20
[2016-12-07 01:03:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:03:33] current cores used: 0/20
[2016-12-07 01:03:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:03:45] current cores used: 0/20
[2016-12-07 01:03:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:03:57] current cores used: 0/20
[2016-12-07 01:03:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:04:09] current cores used: 0/20
[2016-12-07 01:04:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:04:21] current cores used: 0/20
[2016-12-07 01:04:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:04:33] current cores used: 0/20
[2016-12-07 01:04:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:04:45] current cores used: 0/20
[2016-12-07 01:04:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:04:57] current cores used: 0/20
[2016-12-07 01:04:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:05:09] current cores used: 0/20
[2016-12-07 01:05:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:05:21] current cores used: 0/20
[2016-12-07 01:05:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:05:33] current cores used: 0/20
[2016-12-07 01:05:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:05:45] current cores used: 0/20
[2016-12-07 01:05:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:05:57] current cores used: 0/20
[2016-12-07 01:05:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:06:09] current cores used: 0/20
[2016-12-07 01:06:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:06:21] current cores used: 0/20
[2016-12-07 01:06:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:06:33] current cores used: 0/20
[2016-12-07 01:06:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:06:45] current cores used: 0/20
[2016-12-07 01:06:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:06:57] current cores used: 0/20
[2016-12-07 01:06:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:07:09] current cores used: 0/20
[2016-12-07 01:07:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:07:21] current cores used: 0/20
[2016-12-07 01:07:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:07:33] current cores used: 0/20
[2016-12-07 01:07:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:07:46] current cores used: 0/20
[2016-12-07 01:07:46] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:07:58] current cores used: 0/20
[2016-12-07 01:07:58] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:08:10] current cores used: 0/20
[2016-12-07 01:08:10] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:08:22] current cores used: 0/20
[2016-12-07 01:08:22] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:08:34] current cores used: 0/20
[2016-12-07 01:08:34] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:08:46] current cores used: 0/20
[2016-12-07 01:08:46] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:08:58] current cores used: 0/20
[2016-12-07 01:08:58] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:09:10] current cores used: 0/20
[2016-12-07 01:09:10] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:09:22] current cores used: 0/20
[2016-12-07 01:09:22] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:09:34] current cores used: 0/20
[2016-12-07 01:09:34] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:09:46] current cores used: 0/20
[2016-12-07 01:09:46] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:09:58] current cores used: 0/20
[2016-12-07 01:09:58] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:10:10] current cores used: 0/20
[2016-12-07 01:10:10] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:10:22] current cores used: 0/20
[2016-12-07 01:10:22] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:10:34] current cores used: 0/20
[2016-12-07 01:10:34] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:10:46] current cores used: 0/20
[2016-12-07 01:10:46] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:10:58] current cores used: 0/20
[2016-12-07 01:10:58] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:11:10] current cores used: 0/20
[2016-12-07 01:11:10] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:11:22] current cores used: 0/20
[2016-12-07 01:11:22] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:11:34] current cores used: 0/20
[2016-12-07 01:11:34] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:11:46] current cores used: 0/20
[2016-12-07 01:11:46] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:11:58] current cores used: 0/20
[2016-12-07 01:11:58] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:12:10] current cores used: 0/20
[2016-12-07 01:12:10] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:12:22] current cores used: 0/20
[2016-12-07 01:12:22] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:12:34] current cores used: 0/20
[2016-12-07 01:12:34] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:12:46] current cores used: 0/20
[2016-12-07 01:12:46] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:12:58] current cores used: 0/20
[2016-12-07 01:12:58] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:13:10] current cores used: 0/20
[2016-12-07 01:13:10] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:13:22] current cores used: 0/20
[2016-12-07 01:13:22] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:13:34] current cores used: 0/20
[2016-12-07 01:13:34] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:13:46] current cores used: 0/20
[2016-12-07 01:13:46] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:13:58] current cores used: 0/20
[2016-12-07 01:13:58] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:14:10] current cores used: 0/20
[2016-12-07 01:14:10] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:14:22] current cores used: 0/20
[2016-12-07 01:14:22] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:14:35] current cores used: 0/20
[2016-12-07 01:14:35] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:14:47] current cores used: 0/20
[2016-12-07 01:14:47] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:14:59] current cores used: 0/20
[2016-12-07 01:14:59] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:15:11] current cores used: 0/20
[2016-12-07 01:15:11] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:15:23] current cores used: 0/20
[2016-12-07 01:15:23] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:15:35] current cores used: 0/20
[2016-12-07 01:15:35] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:15:47] current cores used: 0/20
[2016-12-07 01:15:47] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:15:59] current cores used: 0/20
[2016-12-07 01:15:59] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:16:11] current cores used: 0/20
[2016-12-07 01:16:11] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:16:23] current cores used: 0/20
[2016-12-07 01:16:23] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:16:35] current cores used: 0/20
[2016-12-07 01:16:35] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:16:47] current cores used: 0/20
[2016-12-07 01:16:47] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:16:59] current cores used: 0/20
[2016-12-07 01:16:59] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:17:11] current cores used: 0/20
[2016-12-07 01:17:11] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:17:23] current cores used: 0/20
[2016-12-07 01:17:23] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:17:35] current cores used: 0/20
[2016-12-07 01:17:35] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:17:47] current cores used: 0/20
[2016-12-07 01:17:47] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:17:59] current cores used: 0/20
[2016-12-07 01:17:59] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:18:11] current cores used: 0/20
[2016-12-07 01:18:11] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:18:23] current cores used: 0/20
[2016-12-07 01:18:23] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:18:35] current cores used: 0/20
[2016-12-07 01:18:35] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:18:47] current cores used: 0/20
[2016-12-07 01:18:47] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:18:59] current cores used: 0/20
[2016-12-07 01:18:59] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:19:11] current cores used: 0/20
[2016-12-07 01:19:11] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:19:23] current cores used: 0/20
[2016-12-07 01:19:23] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:19:35] current cores used: 0/20
[2016-12-07 01:19:35] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:19:47] current cores used: 0/20
[2016-12-07 01:19:47] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:19:59] current cores used: 0/20
[2016-12-07 01:19:59] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:20:11] current cores used: 0/20
[2016-12-07 01:20:11] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:20:23] current cores used: 0/20
[2016-12-07 01:20:23] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:20:35] current cores used: 0/20
[2016-12-07 01:20:35] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:20:47] current cores used: 0/20
[2016-12-07 01:20:47] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:21:00] current cores used: 0/20
[2016-12-07 01:21:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:21:12] current cores used: 0/20
[2016-12-07 01:21:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:21:24] current cores used: 0/20
[2016-12-07 01:21:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:21:36] current cores used: 0/20
[2016-12-07 01:21:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:21:48] current cores used: 0/20
[2016-12-07 01:21:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:22:00] current cores used: 0/20
[2016-12-07 01:22:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:22:12] current cores used: 0/20
[2016-12-07 01:22:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:22:24] current cores used: 0/20
[2016-12-07 01:22:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:22:36] current cores used: 0/20
[2016-12-07 01:22:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:22:48] current cores used: 0/20
[2016-12-07 01:22:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:23:00] current cores used: 0/20
[2016-12-07 01:23:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:23:12] current cores used: 0/20
[2016-12-07 01:23:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:23:24] current cores used: 0/20
[2016-12-07 01:23:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:23:36] current cores used: 0/20
[2016-12-07 01:23:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:23:48] current cores used: 0/20
[2016-12-07 01:23:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:24:00] current cores used: 0/20
[2016-12-07 01:24:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:24:12] current cores used: 0/20
[2016-12-07 01:24:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:24:24] current cores used: 0/20
[2016-12-07 01:24:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:24:36] current cores used: 0/20
[2016-12-07 01:24:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:24:48] current cores used: 0/20
[2016-12-07 01:24:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:25:00] current cores used: 0/20
[2016-12-07 01:25:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:25:12] current cores used: 0/20
[2016-12-07 01:25:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:25:24] current cores used: 0/20
[2016-12-07 01:25:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:25:36] current cores used: 0/20
[2016-12-07 01:25:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:25:48] current cores used: 0/20
[2016-12-07 01:25:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:26:00] current cores used: 0/20
[2016-12-07 01:26:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:26:12] current cores used: 0/20
[2016-12-07 01:26:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:26:24] current cores used: 0/20
[2016-12-07 01:26:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:26:36] current cores used: 0/20
[2016-12-07 01:26:36] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:26:48] current cores used: 0/20
[2016-12-07 01:26:48] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:27:00] current cores used: 0/20
[2016-12-07 01:27:00] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:27:12] current cores used: 0/20
[2016-12-07 01:27:12] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:27:24] current cores used: 0/20
[2016-12-07 01:27:24] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:27:37] current cores used: 0/20
[2016-12-07 01:27:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:27:49] current cores used: 0/20
[2016-12-07 01:27:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:28:01] current cores used: 0/20
[2016-12-07 01:28:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:28:13] current cores used: 0/20
[2016-12-07 01:28:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:28:25] current cores used: 0/20
[2016-12-07 01:28:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:28:37] current cores used: 0/20
[2016-12-07 01:28:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:28:49] current cores used: 0/20
[2016-12-07 01:28:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:29:01] current cores used: 0/20
[2016-12-07 01:29:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:29:13] current cores used: 0/20
[2016-12-07 01:29:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:29:25] current cores used: 0/20
[2016-12-07 01:29:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:29:37] current cores used: 0/20
[2016-12-07 01:29:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:29:49] current cores used: 0/20
[2016-12-07 01:29:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:30:01] current cores used: 0/20
[2016-12-07 01:30:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:30:13] current cores used: 0/20
[2016-12-07 01:30:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:30:25] current cores used: 0/20
[2016-12-07 01:30:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:30:37] current cores used: 0/20
[2016-12-07 01:30:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:30:49] current cores used: 0/20
[2016-12-07 01:30:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:31:01] current cores used: 0/20
[2016-12-07 01:31:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:31:13] current cores used: 0/20
[2016-12-07 01:31:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:31:25] current cores used: 0/20
[2016-12-07 01:31:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:31:37] current cores used: 0/20
[2016-12-07 01:31:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:31:49] current cores used: 0/20
[2016-12-07 01:31:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:32:01] current cores used: 0/20
[2016-12-07 01:32:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:32:13] current cores used: 0/20
[2016-12-07 01:32:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:32:25] current cores used: 0/20
[2016-12-07 01:32:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:32:37] current cores used: 0/20
[2016-12-07 01:32:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:32:49] current cores used: 0/20
[2016-12-07 01:32:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:33:01] current cores used: 0/20
[2016-12-07 01:33:01] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:33:13] current cores used: 0/20
[2016-12-07 01:33:13] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:33:25] current cores used: 0/20
[2016-12-07 01:33:25] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:33:37] current cores used: 0/20
[2016-12-07 01:33:37] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:33:49] current cores used: 0/20
[2016-12-07 01:33:49] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:34:02] current cores used: 0/20
[2016-12-07 01:34:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:34:14] current cores used: 0/20
[2016-12-07 01:34:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:34:26] current cores used: 0/20
[2016-12-07 01:34:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:34:38] current cores used: 0/20
[2016-12-07 01:34:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:34:50] current cores used: 0/20
[2016-12-07 01:34:50] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:35:02] current cores used: 0/20
[2016-12-07 01:35:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:35:14] current cores used: 0/20
[2016-12-07 01:35:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:35:26] current cores used: 0/20
[2016-12-07 01:35:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:35:38] current cores used: 0/20
[2016-12-07 01:35:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:35:50] current cores used: 0/20
[2016-12-07 01:35:50] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:36:02] current cores used: 0/20
[2016-12-07 01:36:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:36:14] current cores used: 0/20
[2016-12-07 01:36:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:36:26] current cores used: 0/20
[2016-12-07 01:36:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:36:38] current cores used: 0/20
[2016-12-07 01:36:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:36:50] current cores used: 0/20
[2016-12-07 01:36:50] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:37:02] current cores used: 0/20
[2016-12-07 01:37:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:37:14] current cores used: 0/20
[2016-12-07 01:37:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:37:26] current cores used: 0/20
[2016-12-07 01:37:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:37:38] current cores used: 0/20
[2016-12-07 01:37:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:37:50] current cores used: 0/20
[2016-12-07 01:37:50] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:38:02] current cores used: 0/20
[2016-12-07 01:38:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:38:14] current cores used: 0/20
[2016-12-07 01:38:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:38:26] current cores used: 0/20
[2016-12-07 01:38:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:38:38] current cores used: 0/20
[2016-12-07 01:38:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:38:50] current cores used: 0/20
[2016-12-07 01:38:50] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:39:02] current cores used: 0/20
[2016-12-07 01:39:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:39:14] current cores used: 0/20
[2016-12-07 01:39:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:39:26] current cores used: 0/20
[2016-12-07 01:39:26] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:39:38] current cores used: 0/20
[2016-12-07 01:39:38] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:39:50] current cores used: 0/20
[2016-12-07 01:39:50] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:40:02] current cores used: 0/20
[2016-12-07 01:40:02] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:40:14] current cores used: 0/20
[2016-12-07 01:40:14] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:40:27] current cores used: 0/20
[2016-12-07 01:40:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:40:39] current cores used: 0/20
[2016-12-07 01:40:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:40:51] current cores used: 0/20
[2016-12-07 01:40:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:41:03] current cores used: 0/20
[2016-12-07 01:41:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:41:15] current cores used: 0/20
[2016-12-07 01:41:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:41:27] current cores used: 0/20
[2016-12-07 01:41:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:41:39] current cores used: 0/20
[2016-12-07 01:41:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:41:51] current cores used: 0/20
[2016-12-07 01:41:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:42:03] current cores used: 0/20
[2016-12-07 01:42:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:42:15] current cores used: 0/20
[2016-12-07 01:42:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:42:27] current cores used: 0/20
[2016-12-07 01:42:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:42:39] current cores used: 0/20
[2016-12-07 01:42:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:42:51] current cores used: 0/20
[2016-12-07 01:42:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:43:03] current cores used: 0/20
[2016-12-07 01:43:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:43:15] current cores used: 0/20
[2016-12-07 01:43:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:43:27] current cores used: 0/20
[2016-12-07 01:43:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:43:39] current cores used: 0/20
[2016-12-07 01:43:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:43:51] current cores used: 0/20
[2016-12-07 01:43:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:44:03] current cores used: 0/20
[2016-12-07 01:44:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:44:15] current cores used: 0/20
[2016-12-07 01:44:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:44:27] current cores used: 0/20
[2016-12-07 01:44:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:44:39] current cores used: 0/20
[2016-12-07 01:44:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:44:51] current cores used: 0/20
[2016-12-07 01:44:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:45:03] current cores used: 0/20
[2016-12-07 01:45:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:45:15] current cores used: 0/20
[2016-12-07 01:45:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:45:27] current cores used: 0/20
[2016-12-07 01:45:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:45:39] current cores used: 0/20
[2016-12-07 01:45:39] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:45:51] current cores used: 0/20
[2016-12-07 01:45:51] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:46:03] current cores used: 0/20
[2016-12-07 01:46:03] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:46:15] current cores used: 0/20
[2016-12-07 01:46:15] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:46:27] current cores used: 0/20
[2016-12-07 01:46:27] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:46:40] current cores used: 0/20
[2016-12-07 01:46:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:46:52] current cores used: 0/20
[2016-12-07 01:46:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:47:04] current cores used: 0/20
[2016-12-07 01:47:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:47:16] current cores used: 0/20
[2016-12-07 01:47:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:47:28] current cores used: 0/20
[2016-12-07 01:47:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:47:40] current cores used: 0/20
[2016-12-07 01:47:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:47:52] current cores used: 0/20
[2016-12-07 01:47:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:48:04] current cores used: 0/20
[2016-12-07 01:48:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:48:16] current cores used: 0/20
[2016-12-07 01:48:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:48:28] current cores used: 0/20
[2016-12-07 01:48:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:48:40] current cores used: 0/20
[2016-12-07 01:48:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:48:52] current cores used: 0/20
[2016-12-07 01:48:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:49:04] current cores used: 0/20
[2016-12-07 01:49:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:49:16] current cores used: 0/20
[2016-12-07 01:49:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:49:28] current cores used: 0/20
[2016-12-07 01:49:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:49:40] current cores used: 0/20
[2016-12-07 01:49:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:49:52] current cores used: 0/20
[2016-12-07 01:49:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:50:04] current cores used: 0/20
[2016-12-07 01:50:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:50:16] current cores used: 0/20
[2016-12-07 01:50:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:50:28] current cores used: 0/20
[2016-12-07 01:50:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:50:40] current cores used: 0/20
[2016-12-07 01:50:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:50:52] current cores used: 0/20
[2016-12-07 01:50:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:51:04] current cores used: 0/20
[2016-12-07 01:51:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:51:16] current cores used: 0/20
[2016-12-07 01:51:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:51:28] current cores used: 0/20
[2016-12-07 01:51:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:51:40] current cores used: 0/20
[2016-12-07 01:51:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:51:52] current cores used: 0/20
[2016-12-07 01:51:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:52:04] current cores used: 0/20
[2016-12-07 01:52:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:52:16] current cores used: 0/20
[2016-12-07 01:52:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:52:28] current cores used: 0/20
[2016-12-07 01:52:28] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:52:40] current cores used: 0/20
[2016-12-07 01:52:40] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:52:52] current cores used: 0/20
[2016-12-07 01:52:52] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:53:04] current cores used: 0/20
[2016-12-07 01:53:04] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:53:16] current cores used: 0/20
[2016-12-07 01:53:16] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:53:29] current cores used: 0/20
[2016-12-07 01:53:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:53:41] current cores used: 0/20
[2016-12-07 01:53:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:53:53] current cores used: 0/20
[2016-12-07 01:53:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:54:05] current cores used: 0/20
[2016-12-07 01:54:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:54:17] current cores used: 0/20
[2016-12-07 01:54:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:54:29] current cores used: 0/20
[2016-12-07 01:54:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:54:41] current cores used: 0/20
[2016-12-07 01:54:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:54:53] current cores used: 0/20
[2016-12-07 01:54:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:55:05] current cores used: 0/20
[2016-12-07 01:55:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:55:17] current cores used: 0/20
[2016-12-07 01:55:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:55:29] current cores used: 0/20
[2016-12-07 01:55:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:55:41] current cores used: 0/20
[2016-12-07 01:55:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:55:53] current cores used: 0/20
[2016-12-07 01:55:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:56:05] current cores used: 0/20
[2016-12-07 01:56:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:56:17] current cores used: 0/20
[2016-12-07 01:56:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:56:29] current cores used: 0/20
[2016-12-07 01:56:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:56:41] current cores used: 0/20
[2016-12-07 01:56:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:56:53] current cores used: 0/20
[2016-12-07 01:56:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:57:05] current cores used: 0/20
[2016-12-07 01:57:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:57:17] current cores used: 0/20
[2016-12-07 01:57:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:57:29] current cores used: 0/20
[2016-12-07 01:57:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:57:41] current cores used: 0/20
[2016-12-07 01:57:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:57:53] current cores used: 0/20
[2016-12-07 01:57:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:58:05] current cores used: 0/20
[2016-12-07 01:58:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:58:17] current cores used: 0/20
[2016-12-07 01:58:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:58:29] current cores used: 0/20
[2016-12-07 01:58:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:58:41] current cores used: 0/20
[2016-12-07 01:58:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:58:53] current cores used: 0/20
[2016-12-07 01:58:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:59:05] current cores used: 0/20
[2016-12-07 01:59:05] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:59:17] current cores used: 0/20
[2016-12-07 01:59:17] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:59:29] current cores used: 0/20
[2016-12-07 01:59:29] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:59:41] current cores used: 0/20
[2016-12-07 01:59:41] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 01:59:53] current cores used: 0/20
[2016-12-07 01:59:53] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:00:06] current cores used: 0/20
[2016-12-07 02:00:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:00:18] current cores used: 0/20
[2016-12-07 02:00:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:00:30] current cores used: 0/20
[2016-12-07 02:00:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:00:42] current cores used: 0/20
[2016-12-07 02:00:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:00:54] current cores used: 0/20
[2016-12-07 02:00:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:01:06] current cores used: 0/20
[2016-12-07 02:01:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:01:18] current cores used: 0/20
[2016-12-07 02:01:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:01:30] current cores used: 0/20
[2016-12-07 02:01:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:01:42] current cores used: 0/20
[2016-12-07 02:01:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:01:54] current cores used: 0/20
[2016-12-07 02:01:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:02:06] current cores used: 0/20
[2016-12-07 02:02:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:02:18] current cores used: 0/20
[2016-12-07 02:02:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:02:30] current cores used: 0/20
[2016-12-07 02:02:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:02:42] current cores used: 0/20
[2016-12-07 02:02:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:02:54] current cores used: 0/20
[2016-12-07 02:02:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:03:06] current cores used: 0/20
[2016-12-07 02:03:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:03:18] current cores used: 0/20
[2016-12-07 02:03:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:03:30] current cores used: 0/20
[2016-12-07 02:03:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:03:42] current cores used: 0/20
[2016-12-07 02:03:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:03:54] current cores used: 0/20
[2016-12-07 02:03:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:04:06] current cores used: 0/20
[2016-12-07 02:04:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:04:18] current cores used: 0/20
[2016-12-07 02:04:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:04:30] current cores used: 0/20
[2016-12-07 02:04:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:04:42] current cores used: 0/20
[2016-12-07 02:04:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:04:54] current cores used: 0/20
[2016-12-07 02:04:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:05:06] current cores used: 0/20
[2016-12-07 02:05:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:05:18] current cores used: 0/20
[2016-12-07 02:05:18] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:05:30] current cores used: 0/20
[2016-12-07 02:05:30] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:05:42] current cores used: 0/20
[2016-12-07 02:05:42] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:05:54] current cores used: 0/20
[2016-12-07 02:05:54] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:06:06] current cores used: 0/20
[2016-12-07 02:06:06] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:06:19] current cores used: 0/20
[2016-12-07 02:06:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:06:31] current cores used: 0/20
[2016-12-07 02:06:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:06:43] current cores used: 0/20
[2016-12-07 02:06:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:06:55] current cores used: 0/20
[2016-12-07 02:06:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:07:07] current cores used: 0/20
[2016-12-07 02:07:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:07:19] current cores used: 0/20
[2016-12-07 02:07:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:07:31] current cores used: 0/20
[2016-12-07 02:07:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:07:43] current cores used: 0/20
[2016-12-07 02:07:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:07:55] current cores used: 0/20
[2016-12-07 02:07:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:08:07] current cores used: 0/20
[2016-12-07 02:08:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:08:19] current cores used: 0/20
[2016-12-07 02:08:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:08:31] current cores used: 0/20
[2016-12-07 02:08:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:08:43] current cores used: 0/20
[2016-12-07 02:08:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:08:55] current cores used: 0/20
[2016-12-07 02:08:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:09:07] current cores used: 0/20
[2016-12-07 02:09:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:09:19] current cores used: 0/20
[2016-12-07 02:09:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:09:31] current cores used: 0/20
[2016-12-07 02:09:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:09:43] current cores used: 0/20
[2016-12-07 02:09:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:09:55] current cores used: 0/20
[2016-12-07 02:09:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:10:07] current cores used: 0/20
[2016-12-07 02:10:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:10:19] current cores used: 0/20
[2016-12-07 02:10:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:10:31] current cores used: 0/20
[2016-12-07 02:10:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:10:43] current cores used: 0/20
[2016-12-07 02:10:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:10:55] current cores used: 0/20
[2016-12-07 02:10:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:11:07] current cores used: 0/20
[2016-12-07 02:11:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:11:19] current cores used: 0/20
[2016-12-07 02:11:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:11:31] current cores used: 0/20
[2016-12-07 02:11:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:11:43] current cores used: 0/20
[2016-12-07 02:11:43] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:11:55] current cores used: 0/20
[2016-12-07 02:11:55] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:12:07] current cores used: 0/20
[2016-12-07 02:12:07] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:12:19] current cores used: 0/20
[2016-12-07 02:12:19] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:12:31] current cores used: 0/20
[2016-12-07 02:12:31] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:12:44] current cores used: 0/20
[2016-12-07 02:12:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:12:56] current cores used: 0/20
[2016-12-07 02:12:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:13:08] current cores used: 0/20
[2016-12-07 02:13:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:13:20] current cores used: 0/20
[2016-12-07 02:13:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:13:32] current cores used: 0/20
[2016-12-07 02:13:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:13:44] current cores used: 0/20
[2016-12-07 02:13:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:13:56] current cores used: 0/20
[2016-12-07 02:13:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:14:08] current cores used: 0/20
[2016-12-07 02:14:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:14:20] current cores used: 0/20
[2016-12-07 02:14:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:14:32] current cores used: 0/20
[2016-12-07 02:14:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:14:44] current cores used: 0/20
[2016-12-07 02:14:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:14:56] current cores used: 0/20
[2016-12-07 02:14:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:15:08] current cores used: 0/20
[2016-12-07 02:15:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:15:20] current cores used: 0/20
[2016-12-07 02:15:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:15:32] current cores used: 0/20
[2016-12-07 02:15:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:15:44] current cores used: 0/20
[2016-12-07 02:15:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:15:56] current cores used: 0/20
[2016-12-07 02:15:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:16:08] current cores used: 0/20
[2016-12-07 02:16:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:16:20] current cores used: 0/20
[2016-12-07 02:16:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:16:32] current cores used: 0/20
[2016-12-07 02:16:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:16:44] current cores used: 0/20
[2016-12-07 02:16:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:16:56] current cores used: 0/20
[2016-12-07 02:16:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:17:08] current cores used: 0/20
[2016-12-07 02:17:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:17:20] current cores used: 0/20
[2016-12-07 02:17:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:17:32] current cores used: 0/20
[2016-12-07 02:17:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:17:44] current cores used: 0/20
[2016-12-07 02:17:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:17:56] current cores used: 0/20
[2016-12-07 02:17:56] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:18:08] current cores used: 0/20
[2016-12-07 02:18:08] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:18:20] current cores used: 0/20
[2016-12-07 02:18:20] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:18:32] current cores used: 0/20
[2016-12-07 02:18:32] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:18:44] current cores used: 0/20
[2016-12-07 02:18:44] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:18:57] current cores used: 0/20
[2016-12-07 02:18:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:19:09] current cores used: 0/20
[2016-12-07 02:19:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:19:21] current cores used: 0/20
[2016-12-07 02:19:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:19:33] current cores used: 0/20
[2016-12-07 02:19:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:19:45] current cores used: 0/20
[2016-12-07 02:19:45] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:19:57] current cores used: 0/20
[2016-12-07 02:19:57] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:20:09] current cores used: 0/20
[2016-12-07 02:20:09] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:20:21] current cores used: 0/20
[2016-12-07 02:20:21] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:20:33] current cores used: 0/20
[2016-12-07 02:20:33] last job submit (parse_set_025) not completed, retry again in 12 sec
[2016-12-07 02:20:45] current cores used: 0/20
[2016-12-07 02:20:45] last job submit (parse_set_025) not completed, retry again in 12 sec
